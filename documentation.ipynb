{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Fraud Detection Project - CA2**\n",
    "\n",
    "## **1. Introduction**\n",
    "\n",
    "### Project Overview\n",
    "This project is the second phase (CA2) of a comprehensive fraud detection system for **SP-Buy**, an e-commerce platform. Building on the work done in **CA1**, which involved data ingestion, exploratory data analysis (EDA), and the creation of an interactive dashboard, this phase focuses on developing a machine learning model to predict fraudulent orders. The goal is to deploy this model in a user-friendly application that the operations team can use to proactively identify and mitigate fraud.\n",
    "\n",
    "### Problem Statement\n",
    "Fraudulent activities pose a significant threat to e-commerce platforms, leading to financial losses, reputational damage, and customer dissatisfaction. Detecting fraud in real-time is challenging due to the imbalanced nature of the data (fraud cases are rare compared to legitimate transactions) and the evolving tactics of fraudsters. In this project, we aim to build a robust machine learning model that can accurately identify fraudulent orders based on historical data.\n",
    "\n",
    "### CA1 1 Recap\n",
    "In **CA1 1**, we performed extensive exploratory data analysis (EDA) and data cleaning on the provided datasets:\n",
    "- **Customer Features**: Information about customers, such as their order history and verification status.\n",
    "- **Order Features**: Details about each order, including payment method and order value.\n",
    "- **Labels**: Fraud labels indicating whether an order was fraudulent.\n",
    "\n",
    "The cleaned and preprocessed data was used to create an interactive dashboard for monitoring fraud trends and patterns. This dashboard provided valuable insights into the dataset, enabling stakeholders to understand the nature of fraud on the platform.\n",
    "\n",
    "### CA2 Objectives\n",
    "In **CA2**, we shift our focus to **model development** and **deployment**. The key objectives are:\n",
    "1. **Advanced Data Analysis**:\n",
    "   - Perform additional EDA to identify feature importance and detect outliers, which are critical for model creation.\n",
    "2. **Model Development**:\n",
    "   - Train, evaluate, and optimize machine learning models to predict fraudulent orders.\n",
    "3. **Experiment Tracking**:\n",
    "   - Use **MLflow** to track experiments, log parameters, and compare model performance.\n",
    "4. **Deployment**:\n",
    "   - Develop a **Tkinter-based GUI application** to allow the operations team to make predictions on new orders.\n",
    "5. **Automation**:\n",
    "   - Design the workflow to be modular and scalable, enabling future integration with **Airflow** for automation.\n",
    "\n",
    "### Key Challenges\n",
    "- **Imbalanced Data**: Fraud cases are rare, making it challenging to train a model that can accurately detect them.\n",
    "- **Feature Engineering**: Identifying and creating meaningful features that improve model performance.\n",
    "- **Deciding how to proceed with experiments**: Balancing the need for thorough experimentation with time constraints was a key challenge. We addressed this by prioritizing techniques likely to have the most impact (e.g., handling imbalanced data, feature engineering).\n",
    "\n",
    "### Structure of the Report\n",
    "This report documents the entire process of **CA2**, from advanced data analysis and model development to deployment and automation. The following sections provide a detailed breakdown of each step:\n",
    "- **Exploratory Data Analysis (EDA)**: Additional analysis focusing on feature importance and outlier detection.\n",
    "- **Feature Engineering**: Creation of new features and their impact on model performance.\n",
    "- **Data Preprocessing**: Techniques used to prepare the data for modeling.\n",
    "- **Model Training and Evaluation**: Development and comparison of machine learning models.\n",
    "- **Deployment**: Development of the GUI application and integration of the final model.\n",
    "- **Conclusion**: Summary of findings, challenges, and future work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. Preparing the Dataset and Libraries**\n",
    "\n",
    "---\n",
    "\n",
    "#### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import warnings\n",
    "import itertools\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "from ExperimentTracker2 import PhaseOneExperimentTracker\n",
    "\n",
    "# Data processing and analysis\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    OneHotEncoder,\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTENC, RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from dask_ml.model_selection import train_test_split as dask_train_test_split\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Model evaluation and pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# MLflow for experiment tracking\n",
    "import mlflow\n",
    "\n",
    "# Initialize Dask client for parallel processing\n",
    "client = Client()\n",
    "\n",
    "# Show all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# ## SQL Server Name and Database Name\n",
    "# server = 'yj\\SQLEXPRESS'\n",
    "# database = 'PAI_CA1'\n",
    "\n",
    "# ## Create a connection to the SQL Server\n",
    "# engine = create_engine('mssql+pyodbc://{}/{}?driver=ODBC Driver 17 for SQL Server'.format(server, database))\n",
    "\n",
    "# customer_df = pd.read_sql('SELECT * FROM [dbo].[clean-data-customer_v1.0]', engine)\n",
    "# order_df = pd.read_sql('SELECT * FROM [dbo].[clean-data-order_v1.0]', engine)\n",
    "# label_df = pd.read_sql('SELECT * FROM [dbo].[clean-data-label_v1.0]', engine)\n",
    "\n",
    "\n",
    "# # Drop index column\n",
    "# customer_df.drop(columns=['index'], inplace=True)\n",
    "# order_df.drop(columns=['index'], inplace=True)\n",
    "# label_df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "# # merge the data\n",
    "# merged_df = pd.merge(label_df, customer_df, on=['customer_id', 'country_code'], how='inner')\n",
    "# merged_df = pd.merge(merged_df, order_df, on=['order_id', 'country_code'], how='inner')\n",
    "\n",
    "# merged_df.to_csv('merged_data.csv', index=False)\n",
    "\n",
    "data = pd.read_csv('./data/merged_data.csv')\n",
    "\n",
    "merged_df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>mobile_verified</th>\n",
       "      <th>num_orders_last_50days</th>\n",
       "      <th>num_cancelled_orders_last_50days</th>\n",
       "      <th>num_refund_orders_last_50days</th>\n",
       "      <th>total_payment_last_50days</th>\n",
       "      <th>num_associated_customers</th>\n",
       "      <th>first_order_datetime</th>\n",
       "      <th>collect_type</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>order_value</th>\n",
       "      <th>num_items_ordered</th>\n",
       "      <th>refund_value</th>\n",
       "      <th>order_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BD</td>\n",
       "      <td>w2lx-myz3</td>\n",
       "      <td>bdpr8uva</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-08-13 03:53:52</td>\n",
       "      <td>delivery</td>\n",
       "      <td>PayOnDelivery</td>\n",
       "      <td>8.664062</td>\n",
       "      <td>9</td>\n",
       "      <td>0.870117</td>\n",
       "      <td>2023-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BD</td>\n",
       "      <td>ta7z-r91q</td>\n",
       "      <td>bd59rlzo</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228.042468</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-05-08 14:29:19</td>\n",
       "      <td>delivery</td>\n",
       "      <td>CreditCard</td>\n",
       "      <td>21.859375</td>\n",
       "      <td>4</td>\n",
       "      <td>2.279297</td>\n",
       "      <td>2023-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BD</td>\n",
       "      <td>t5af-wgb2</td>\n",
       "      <td>bd6zhjvq</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.674685</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-08-25 07:47:00</td>\n",
       "      <td>delivery</td>\n",
       "      <td>AFbKash</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.349609</td>\n",
       "      <td>2023-03-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BD</td>\n",
       "      <td>sibu-9lm4</td>\n",
       "      <td>bd4fv4rb</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>279.805231</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-12-06 13:53:22</td>\n",
       "      <td>delivery</td>\n",
       "      <td>CreditCard</td>\n",
       "      <td>4.535156</td>\n",
       "      <td>5</td>\n",
       "      <td>0.150024</td>\n",
       "      <td>2023-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BD</td>\n",
       "      <td>we61-omtr</td>\n",
       "      <td>bdzeepq7</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>107.067610</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-07-04 11:45:39</td>\n",
       "      <td>delivery</td>\n",
       "      <td>PayOnDelivery</td>\n",
       "      <td>3.011719</td>\n",
       "      <td>1</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>2023-01-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code   order_id customer_id  is_fraud  mobile_verified  \\\n",
       "0           BD  w2lx-myz3    bdpr8uva         0             True   \n",
       "1           BD  ta7z-r91q    bd59rlzo         0             True   \n",
       "2           BD  t5af-wgb2    bd6zhjvq         0             True   \n",
       "3           BD  sibu-9lm4    bd4fv4rb         0             True   \n",
       "4           BD  we61-omtr    bdzeepq7         0             True   \n",
       "\n",
       "   num_orders_last_50days  num_cancelled_orders_last_50days  \\\n",
       "0                       0                                 0   \n",
       "1                       7                                 0   \n",
       "2                       4                                 1   \n",
       "3                      19                                 0   \n",
       "4                      30                                 6   \n",
       "\n",
       "   num_refund_orders_last_50days  total_payment_last_50days  \\\n",
       "0                              0                   0.000000   \n",
       "1                              0                 228.042468   \n",
       "2                              0                  45.674685   \n",
       "3                              3                 279.805231   \n",
       "4                              4                 107.067610   \n",
       "\n",
       "   num_associated_customers first_order_datetime collect_type payment_method  \\\n",
       "0                         3  2022-08-13 03:53:52     delivery  PayOnDelivery   \n",
       "1                         4  2022-05-08 14:29:19     delivery     CreditCard   \n",
       "2                         2  2021-08-25 07:47:00     delivery        AFbKash   \n",
       "3                         5  2021-12-06 13:53:22     delivery     CreditCard   \n",
       "4                         5  2020-07-04 11:45:39     delivery  PayOnDelivery   \n",
       "\n",
       "   order_value  num_items_ordered  refund_value  order_date  \n",
       "0     8.664062                  9      0.870117  2023-04-08  \n",
       "1    21.859375                  4      2.279297  2023-02-13  \n",
       "2     7.125000                  1      2.349609  2023-03-06  \n",
       "3     4.535156                  5      0.150024  2023-01-29  \n",
       "4     3.011719                  1      3.750000  2023-01-16  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to appropriate dtypes after importing daset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before conversion: 140.349328 MB\n",
      "Memory usage after conversion: 144.876688 MB\n"
     ]
    }
   ],
   "source": [
    "def convert_dtypes(df):\n",
    "    # Convert 'order_value' and 'refund_value' to float16 for memory efficiency\n",
    "    df['order_value'] = df['order_value'].astype('float32')\n",
    "    df['refund_value'] = df['refund_value'].astype('float32')\n",
    "    \n",
    "    # Convert 'num_items_ordered' to uint8 after rounding\n",
    "    df['num_items_ordered'] = df['num_items_ordered'].astype(float).round().astype('uint8')\n",
    "    \n",
    "    # Convert 'order_date' and 'first_order_datetime' to datetime\n",
    "    df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "    df['first_order_datetime'] = pd.to_datetime(df['first_order_datetime'])\n",
    "    \n",
    "    # Convert categorical columns to category dtype for efficiency\n",
    "    df[['country_code', 'collect_type', 'payment_method']] = df[['country_code', 'collect_type', 'payment_method']].astype('category')\n",
    "    \n",
    "    # Convert numerical columns (those that represent counts or numeric features) to uint16\n",
    "    df[['num_orders_last_50days', 'num_cancelled_orders_last_50days', 'num_refund_orders_last_50days']] = df[['num_orders_last_50days', 'num_cancelled_orders_last_50days', 'num_refund_orders_last_50days']].astype('uint16')\n",
    "    \n",
    "    # Convert 'num_associated_customers' to uint8 for efficient memory usage\n",
    "    df['num_associated_customers'] = df['num_associated_customers'].astype('uint8')\n",
    "    \n",
    "    # Convert 'total_payment_last_50days' to float16 for memory efficiency\n",
    "    df['total_payment_last_50days'] = df['total_payment_last_50days'].astype('float32')\n",
    "    \n",
    "    # Convert 'mobile_verified' and 'is_fraud' columns to boolean (mapping string values)\n",
    "    # df['mobile_verified'] = df['mobile_verified'].map({'True': True, 'False': False})\n",
    "    # df['is_fraud'] = df['is_fraud'].map({'1': True, '0': False})\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Mermory before\n",
    "print(f'Memory usage before conversion: {merged_df.memory_usage().sum() / 1e6} MB')\n",
    "merged_df = convert_dtypes(merged_df)\n",
    "# Mermory after\n",
    "print(f'Memory usage after conversion: {merged_df.memory_usage().sum() / 1e6} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country_code                              category\n",
       "order_id                                    object\n",
       "customer_id                                 object\n",
       "is_fraud                                     int64\n",
       "mobile_verified                               bool\n",
       "num_orders_last_50days                      uint16\n",
       "num_cancelled_orders_last_50days            uint16\n",
       "num_refund_orders_last_50days               uint16\n",
       "total_payment_last_50days                  float16\n",
       "num_associated_customers                     uint8\n",
       "first_order_datetime                datetime64[ns]\n",
       "collect_type                              category\n",
       "payment_method                            category\n",
       "order_value                                float16\n",
       "num_items_ordered                            uint8\n",
       "refund_value                               float16\n",
       "order_date                          datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **3. Exploratory Data Analysis (EDA)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Overview\n",
    "In **CA1**, we performed initial exploratory data analysis (EDA) to understand the structure and distribution of the dataset. This included:\n",
    "\n",
    "- Merging the datasets (customer-features.csv, order-features.csv, labels.csv).\n",
    "\n",
    "- Cleaning the data (e.g., handling missing values, removing duplicates).\n",
    "\n",
    "- Visualizing the distribution of fraud vs. non-fraud cases.\n",
    "\n",
    "In **CA2**, we focus on additional EDA tasks that are essential for model creation:\n",
    "- Imbalanced Data: Check how imbalanced is the dataset\n",
    "\n",
    "- Feature Importance: Identifying which features have the most impact on predicting fraud.\n",
    "\n",
    "- Outlier Detection: Detecting and handling outliers that could skew model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d65005a2c354364a02f135cf24dba9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ebc55b845164432b756eaf4777942f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3953a989e400441599d6177cbf3d3129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c7e2466cc4474982e504bc39223625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## \n",
    "merged_profile = merged_df.profile_report(title='Merged Data Profiling Report', explorative=True)\n",
    "merged_profile.to_file('merged_data_profiling_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imbalanced Data**\n",
    "1. Imbalanced data refers to a situation where the classes in the dataset are not equally represented. According to our pandas profiling report. `Collect Type` is one of these columns that have a high imbalance.\n",
    "\n",
    "<img class=\"text-center\" src=\"images/collect_type_imbalance.png\" width=\"1000\">\n",
    "\n",
    "2. `Mobile Verified` is also another column that has a high imbalance.\n",
    "\n",
    "<img class=\"text-center\" src=\"images/mobile_verified_imbalance.png\" width=\"1000\">\n",
    "\n",
    "3. We can see that these columns are severely imbalanced, which can pose a challenge when training machine learning models. We will test the different sampling methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Outlier Detection**\n",
    "\n",
    "1. Outliers can significantly impact the performance of machine learning models, especially those sensitive to outliers (e.g., linear models). We look at some of the histograms of the numerical columns to identify potential outliers. For the sake of keeping the documentation short, we will not look at all the histograms of the numerical columns.\n",
    "\n",
    "<img class=\"text-center\" src=\"images/histograms/num_canc_orders_last_50.png\" width=\"500\">\n",
    "<img class=\"text-center\" src=\"images/histograms/num_orders_last_50.png\" width=\"500\">\n",
    "<img class=\"text-center\" src=\"images/histograms/num_refund_orders_last_50.png\" width=\"500\">\n",
    "\n",
    "2. We can see that based on the histograms, the data is heavily skewed, indicating the presence of outliers. We will address this issue and test the different outlier handling techniques during the model experimentation phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **4. Model Workflow**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Phase 1`: Baseline Experiments\n",
    "\n",
    "`Preprocessing`: Testing encoding (one-hot encoding, no enconding => drop categorical columns) and scaler types (StandardScaler, MinMaxScaler, RobustScaler, None).\n",
    "\n",
    "`Models`: Logistic Regression, Random Forest, GassianNB, LightGBM, GradientBoosting, DecisionTree\n",
    "\n",
    "`Goal`: Establish baseline performance metrics for scalers and encoding.\n",
    "\n",
    "`Phase 2`: Advanced Preprocessing\n",
    "\n",
    "`Preprocessing`: Testing different imbalanced data handling techniques (SMOTE, RUS, ROS), outlier handling techniques (LOF, ISO).\n",
    "\n",
    "`Models`: Logistic Regression, Random Forest, GassianNB, LightGBM, GradientBoosting, DecisionTree\n",
    "\n",
    "`Goal`: Identify which preprocessing steps improve performance.\n",
    "\n",
    "`Phase 3`: Feature Engineering, Hyperparmeter Tuning, and Selection\n",
    "\n",
    "`First set of Models`: Choose the 2 best-performing type of models, with the best scaler and encode/no encode, and the best imbalanced data handling and outlier handling techniques. and without the best scaler and encode/no encode, and the best imbalanced data handling and outlier handling techniques.\n",
    "\n",
    "`First Goal`: To decide on the best preprocessing steps\n",
    "\n",
    "`Second set of Models`: Apply feature selection techniques (e.g., PCA, feature importance from tree-based models).\n",
    "\n",
    "`Second Goal`: Determine the best model and feature selection techniques and attempt to reduce overfitting if any. (or no feature selection)\n",
    "\n",
    "`Third set of Models`: Apply hyperparameter tuning to the best model.\n",
    "\n",
    "`Third Goal`: Determine the best hyperparameters for the best model, reduce overfitting, and improve performance.\n",
    "\n",
    "`Note`: All these sets of models are trained in the same experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Preprocessing Data Before Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load large dataset with Dask\n",
    "df = dd.read_csv(\"merged_data.csv\")\n",
    "\n",
    "\n",
    "# Convert data types for memory efficiency\n",
    "def convert_dtypes(df):\n",
    "    df[\"order_value\"] = df[\"order_value\"].astype(\"float32\")\n",
    "    df[\"refund_value\"] = df[\"refund_value\"].astype(\"float32\")\n",
    "    df[\"num_items_ordered\"] = (\n",
    "        df[\"num_items_ordered\"].astype(float).round().astype(\"uint8\")\n",
    "    )\n",
    "    df[\"order_date\"] = dd.to_datetime(df[\"order_date\"])\n",
    "    df[\"first_order_datetime\"] = dd.to_datetime(df[\"first_order_datetime\"])\n",
    "    df[[\"country_code\", \"collect_type\", \"payment_method\"]] = df[\n",
    "        [\"country_code\", \"collect_type\", \"payment_method\"]\n",
    "    ].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "\n",
    "df = convert_dtypes(df)\n",
    "\n",
    "\n",
    "# Payment method grouping\n",
    "def group_payment_methods(payment_method):\n",
    "    mapping = {\n",
    "        \"CreditCard\": [\n",
    "            \"GenericCreditCard\",\n",
    "            \"CybersourceCreditCard\",\n",
    "            \"CybersourceApplePay\",\n",
    "            \"CreditCard\",\n",
    "        ],\n",
    "        \"DigitalWallet\": [\"GCash\", \"AFbKash\", \"JazzCashWallet\", \"AdyenBoost\", \"PayPal\"],\n",
    "        \"BankTransfer\": [\"XenditDirectDebit\", \"RazerOnlineBanking\"],\n",
    "        \"PaymentOnDelivery\": [\"Invoice\", \"PayOnDelivery\"],\n",
    "    }\n",
    "    for key, values in mapping.items():\n",
    "        if payment_method in values:\n",
    "            return key\n",
    "    return \"Others\"\n",
    "\n",
    "\n",
    "df[\"payment_method\"] = df[\"payment_method\"].map(group_payment_methods)\n",
    "\n",
    "\n",
    "# Date transformations\n",
    "def date_transformations(df):\n",
    "    df[\"days_since_first_order\"] = (\n",
    "        df[\"order_date\"] - df[\"first_order_datetime\"]\n",
    "    ).dt.days\n",
    "    df = df.drop(columns=[\"first_order_datetime\"])\n",
    "    df[\"order_date_day_of_week\"] = df[\"order_date\"].dt.dayofweek\n",
    "    df[\"order_date_day\"] = df[\"order_date\"].dt.day\n",
    "    df[\"order_date_month\"] = df[\"order_date\"].dt.month\n",
    "    df[\"order_date_year\"] = df[\"order_date\"].dt.year\n",
    "    df = df.drop(columns=[\"order_date\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = date_transformations(df)\n",
    "df = df.drop(columns=[\"order_id\", \"customer_id\"])\n",
    "\n",
    "# Split data\n",
    "X = df.drop(columns=[\"is_fraud\"])\n",
    "y = df[\"is_fraud\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Preparation`: We will first create a baseline model class that will be used to train the models in the different phases. This class will be used to train the models in the different phases using pre-built functions that can be reused in the different phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseExperimentTracker:\n",
    "    def __init__(self, experiment_name, checkpoint_file=\"experiment_checkpoint.json\"):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.checkpoint_file = checkpoint_file\n",
    "        self.completed_runs = self.load_checkpoint()\n",
    "\n",
    "        # Set the environment variables for MLflow\n",
    "        os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://dagshub.com/REHXZ/PAI_CA2.mlflow\"\n",
    "        os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"REHXZ\"\n",
    "        os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = (\n",
    "            \"f70a7da81f0dca4cab7dd6d83138347b7a0d9f98\"\n",
    "        )\n",
    "\n",
    "        # Set MLflow tracking URI to DagsHub\n",
    "        mlflow.set_tracking_uri(\"https://dagshub.com/REHXZ/PAI_CA2.mlflow\")\n",
    "\n",
    "        # Create or get experiment\n",
    "        try:\n",
    "            self.experiment_id = mlflow.create_experiment(experiment_name)\n",
    "        except Exception:\n",
    "            self.experiment_id = mlflow.get_experiment_by_name(\n",
    "                experiment_name\n",
    "            ).experiment_id\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        \"\"\"Load the checkpoint file if it exists.\"\"\"\n",
    "        if os.path.exists(self.checkpoint_file):\n",
    "            with open(self.checkpoint_file, \"r\") as f:\n",
    "                return set(json.load(f))\n",
    "        return set()\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        \"\"\"Save the current progress to checkpoint file.\"\"\"\n",
    "        with open(self.checkpoint_file, \"w\") as f:\n",
    "            json.dump(list(self.completed_runs), f)\n",
    "\n",
    "    def generate_run_id(self, config):\n",
    "        \"\"\"Generate a concise, unique identifier for a run configuration.\"\"\"\n",
    "        model_abbr = config[\"models\"][\"name\"][:2].upper()  # Abbreviate model name\n",
    "        scaler_abbr = config[\"scaler\"].__class__.__name__.replace(\n",
    "            \"Scaler\", \"\"\n",
    "        )  # Simplify scaler name\n",
    "        encoding_status = \"Enc\" if config[\"encode\"][\"apply\"] else \"NoEnc\"\n",
    "        timestamp = time.strftime(\"%Y%m%d%H%M\")  # Add timestamp for uniqueness\n",
    "        return f\"{model_abbr}_{scaler_abbr}_{encoding_status}_{timestamp}\"\n",
    "\n",
    "    def evaluate_metrics(\n",
    "        self, y_train, y_train_pred, y_train_prob, y_test, y_test_pred, y_test_prob\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Calculate and return a dictionary of evaluation metrics for both train and test sets.\n",
    "        \"\"\"\n",
    "        metrics = {\n",
    "            \"train_accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "            \"train_precision\": precision_score(y_train, y_train_pred),\n",
    "            \"train_recall\": recall_score(y_train, y_train_pred),\n",
    "            \"train_f1_score\": f1_score(y_train, y_train_pred),\n",
    "            \"train_roc_auc\": roc_auc_score(y_train, y_train_prob),\n",
    "            \"train_pr_auc\": average_precision_score(y_train, y_train_prob),\n",
    "            \"test_accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "            \"test_precision\": precision_score(y_test, y_test_pred),\n",
    "            \"test_recall\": recall_score(y_test, y_test_pred),\n",
    "            \"test_f1_score\": f1_score(y_test, y_test_pred),\n",
    "            \"test_roc_auc\": roc_auc_score(y_test, y_test_prob),\n",
    "            \"test_pr_auc\": average_precision_score(y_test, y_test_prob),\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    # def log_mean_fit_time(self, total_fit_time, num_runs):\n",
    "    #     \"\"\"Calculate and log the mean fit time for the model.\"\"\"\n",
    "    #     mlflow.log_metric(\"Total_Fit_Time\", total_fit_time)\n",
    "    #     mlflow.log_metric(\"Num_Runs\", total_fit_time / num_runs)\n",
    "\n",
    "    def plot_learning_curves(self, pipeline, X, y, cv=5):\n",
    "        \"\"\"\n",
    "        Generate and save learning curves.\n",
    "        \"\"\"\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            pipeline, X, y, cv=cv, scoring=\"f1\", n_jobs=-1\n",
    "        )\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "        # Plot learning curves\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(train_sizes, train_scores_mean, label=\"Training score\")\n",
    "        plt.plot(train_sizes, test_scores_mean, label=\"Cross-validation score\")\n",
    "        plt.xlabel(\"Training examples\")\n",
    "        plt.ylabel(\"F1 Score\")\n",
    "        plt.title(\"Learning Curves\")\n",
    "        plt.legend()\n",
    "\n",
    "        # Save the plot\n",
    "        learning_curve_path = f\"learning_curves_{time.strftime('%Y%m%d_%H%M')}.png\"\n",
    "        plt.savefig(learning_curve_path)\n",
    "        plt.close()\n",
    "        return learning_curve_path\n",
    "\n",
    "    def run_experiments(self):\n",
    "        # To be implemented by subclasses\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Phase 1`: We will start training the baselines models to test the different scalers and if encoding is necessary. (if not necessary, we will drop the categorical columns)\n",
    "\n",
    "`Metrics`: We defined the key metrics we will be using to determine the we will be using to determine the best model. These metrics are: `Accuracy, Precision, Recall, F1-score, ROC-AUC and PR-AUC`. However our main metric will be the F1-score. This is because the `F1-score` is the harmonic mean of precision and recall, and it provides a balance between the two metrics. In the context of fraud detection, we want to minimize false positives (predicting a transaction as fraudulent when it is not) and false negatives (predicting a transaction as legitimate when it is fraudulent). The F1-score is a good metric to evaluate the trade-off between precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseOneExperimentTracker(BaseExperimentTracker):\n",
    "    def run_experiments(\n",
    "        self,\n",
    "        experiment_combinations,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        numeric_columns,\n",
    "        categorical_cols,\n",
    "    ):\n",
    "        \"\"\"Run experiments for Phase 1.\"\"\"\n",
    "        client = Client()  # Initialize Dask client for parallel processing\n",
    "\n",
    "        total_time = 0\n",
    "        for config in experiment_combinations:\n",
    "            run_id = self.generate_run_id(config)\n",
    "            if run_id in self.completed_runs:\n",
    "                print(f\"Skipping completed run: {run_id}\")\n",
    "                continue\n",
    "            print(f\"Starting run: {run_id}\")\n",
    "\n",
    "            try:\n",
    "                with mlflow.start_run(run_name=run_id):\n",
    "                    # Add descriptive run tags\n",
    "                    mlflow.set_tag(\"model_type\", config[\"models\"][\"name\"])\n",
    "                    mlflow.set_tag(\"scaler_type\", config[\"scaler\"].__class__.__name__)\n",
    "                    mlflow.set_tag(\"encoding_applied\", str(config[\"encode\"][\"apply\"]))\n",
    "                    mlflow.set_tag(\"dataset\", \"X_train\")\n",
    "\n",
    "                    # Build preprocessing steps\n",
    "                    transformers = []\n",
    "                    if config[\"scaler\"]:\n",
    "                        transformers.append(\n",
    "                            (\"scaler\", config[\"scaler\"], numeric_columns)\n",
    "                        )\n",
    "                    if config[\"encode\"][\"apply\"]:\n",
    "                        transformers.append(\n",
    "                            (\n",
    "                                \"encoder\",\n",
    "                                OneHotEncoder(\n",
    "                                    handle_unknown=\"ignore\", sparse_output=True\n",
    "                                ),\n",
    "                                categorical_cols,\n",
    "                            )\n",
    "                        )\n",
    "                    else:\n",
    "                        transformers.append(\n",
    "                            (\"drop_categorical\", \"drop\", categorical_cols)\n",
    "                        )\n",
    "\n",
    "                    preprocessor = ColumnTransformer(\n",
    "                        transformers=transformers, remainder=\"passthrough\"\n",
    "                    )\n",
    "                    pipeline = Pipeline(\n",
    "                        steps=[\n",
    "                            (\"preprocessor\", preprocessor),\n",
    "                            (\"model\", config[\"models\"][\"instance\"]),\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "                    # Train the pipeline in parallel using Dask\n",
    "                    pipeline.fit(X_train.compute(), y_train.compute().ravel())\n",
    "\n",
    "                    # Predictions and probabilities for train and test sets\n",
    "                    train_predictions = pipeline.predict(X_train.compute())\n",
    "                    train_probabilities = pipeline.predict_proba(X_train.compute())[\n",
    "                        :, 1\n",
    "                    ]\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    test_predictions = pipeline.predict(X_test.compute())\n",
    "                    test_probabilities = pipeline.predict_proba(X_test.compute())[:, 1]\n",
    "                    total_time += time.time() - start_time\n",
    "\n",
    "                    # Evaluate metrics\n",
    "                    metrics = self.evaluate_metrics(\n",
    "                        y_train.compute(),\n",
    "                        train_predictions,\n",
    "                        train_probabilities,\n",
    "                        y_test.compute(),\n",
    "                        test_predictions,\n",
    "                        test_probabilities,\n",
    "                    )\n",
    "\n",
    "                    # Log parameters, metrics, and model\n",
    "                    mlflow.log_params(config)\n",
    "                    mlflow.log_metrics(metrics)\n",
    "                    average_time = total_time / len(X_train)\n",
    "                    mlflow.log_metric(\"average_prediction_time\", average_time)\n",
    "\n",
    "                    # Log the model with an input example\n",
    "                    mlflow.sklearn.log_model(\n",
    "                        pipeline,\n",
    "                        \"model\",\n",
    "                        input_example=X_train.compute().iloc[\n",
    "                            0:1\n",
    "                        ],  # Convert to Pandas DataFrame before slicing\n",
    "                    )\n",
    "                    # Save learning curves\n",
    "                    learning_curve_path = self.plot_learning_curves(\n",
    "                        pipeline, X_train.compute(), y_train.compute()\n",
    "                    )\n",
    "                    mlflow.log_artifact(\n",
    "                        learning_curve_path, artifact_path=\"learning_curves\"\n",
    "                    )\n",
    "\n",
    "                    # Mark this run as completed\n",
    "                    self.completed_runs.add(run_id)\n",
    "                    self.save_checkpoint()\n",
    "                    print(f\"Completed run: {run_id}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in run {run_id}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "            finally:\n",
    "                print(\"end run\")\n",
    "                mlflow.end_run()  # Ensure the run is properly ended\n",
    "\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Defining Search Space for Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment configurations\n",
    "search_space = {\n",
    "    \"scaler\": [None, StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "    \"encode\": [{\"apply\": True, \"columns\": [\"categorical_col\"]}, {\"apply\": False}],\n",
    "    \"models\": [\n",
    "        {\"name\": \"LogisticRegression\", \"instance\": LogisticRegression()},\n",
    "        {\"name\": \"RandomForest\", \"instance\": RandomForestClassifier()},\n",
    "        {\"name\": \"LightGBM\", \"instance\": LGBMClassifier()},\n",
    "        {\"name\": \"GaussianNB\", \"instance\": GaussianNB()},\n",
    "        {\"name\": \"DecisionTree\", \"instance\": DecisionTreeClassifier()},\n",
    "        {\"name\": \"GradientBoosting\", \"instance\": GradientBoostingClassifier()},\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Generate all combinations\n",
    "keys, values = zip(*search_space.items())\n",
    "experiment_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "categorical_cols = [\"payment_method\", \"country_code\", \"collect_type\"]\n",
    "numeric_columns = [\n",
    "    \"order_value\",\n",
    "    \"refund_value\",\n",
    "    \"num_items_ordered\",\n",
    "    \"days_since_first_order\",\n",
    "    \"order_date_day_of_week\",\n",
    "    \"order_date_day\",\n",
    "    \"order_date_month\",\n",
    "    \"order_date_year\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tracker and run experiments\n",
    "tracker = PhaseOneExperimentTracker(\"Phase1\")\n",
    "tracker.run_experiments(\n",
    "    experiment_combinations,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    numeric_columns,\n",
    "    categorical_cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Results`: Our two best baseline models are Random Forest and LightGBM, with the best scaler being MinMaxScaler and Standard Scaler respectively. Both models perform better with encoding. Next, we will move to the next phase to test the different imbalanced data handling techniques and outlier handling techniques.\n",
    "\n",
    "<img class=\"text-center\" src=\"images/results/phase1.png\" width=\"1500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Phase 2`: We will test the baseline models with different imbalanced data handling techniques (SMOTE, RUS, ROS), outlier handling techniques (LOF, ISO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseTwoExperimentTracker(BaseExperimentTracker):\n",
    "    def run_experiments(\n",
    "        self,\n",
    "        datasets,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        experiment_combinations,\n",
    "        numeric_columns,\n",
    "        categorical_cols,\n",
    "    ):\n",
    "        \"\"\"Run experiments for Phase 2 on multiple datasets.\"\"\"\n",
    "        client = Client()  # Initialize Dask client for parallel processing\n",
    "        total_time = 0\n",
    "        for dataset_name, X_train, y_train in datasets:\n",
    "            for config in experiment_combinations:\n",
    "                run_id = self.generate_run_id(config)\n",
    "                if run_id in self.completed_runs:\n",
    "                    print(f\"Skipping completed run: {run_id}\")\n",
    "                    continue\n",
    "                print(f\"Starting run: {run_id}\")\n",
    "                try:\n",
    "                    with mlflow.start_run(run_name=run_id):\n",
    "                        # Add descriptive run tags\n",
    "                        mlflow.set_tag(\"dataset\", dataset_name)\n",
    "                        mlflow.set_tag(\"model_type\", config[\"models\"][\"name\"])\n",
    "                        mlflow.set_tag(\n",
    "                            \"scaler_type\", config[\"scaler\"].__class__.__name__\n",
    "                        )\n",
    "                        mlflow.set_tag(\n",
    "                            \"encoding_applied\", str(config[\"encode\"][\"apply\"])\n",
    "                        )\n",
    "\n",
    "                        # Split dataset name\n",
    "                        dataset_names = dataset_name.split(\"_\")\n",
    "                        mlflow.set_tag(\n",
    "                            \"outlier_technique\",\n",
    "                            (\n",
    "                                \"LOF\"\n",
    "                                if \"LOF\" in dataset_names\n",
    "                                else \"ISO\" if \"ISO\" in dataset_names else \"None\"\n",
    "                            ),\n",
    "                        )\n",
    "                        mlflow.set_tag(\n",
    "                            \"resampling_method\",\n",
    "                            (\n",
    "                                \"SMOTE\"\n",
    "                                if \"SMOTE\" in dataset_names\n",
    "                                else (\n",
    "                                    \"ROS\"\n",
    "                                    if \"ROS\" in dataset_names\n",
    "                                    else \"RUS\" if \"RUS\" in dataset_names else \"None\"\n",
    "                                )\n",
    "                            ),\n",
    "                        )\n",
    "\n",
    "                        # Build preprocessing steps\n",
    "                        transformers = []\n",
    "                        if config[\"scaler\"]:\n",
    "                            transformers.append(\n",
    "                                (\"scaler\", config[\"scaler\"], numeric_columns)\n",
    "                            )\n",
    "                        if config[\"encode\"][\"apply\"]:\n",
    "                            transformers.append(\n",
    "                                (\n",
    "                                    \"encoder\",\n",
    "                                    OneHotEncoder(\n",
    "                                        handle_unknown=\"ignore\", sparse_output=True\n",
    "                                    ),\n",
    "                                    categorical_cols,\n",
    "                                )\n",
    "                            )\n",
    "                        else:\n",
    "                            transformers.append(\n",
    "                                (\"drop_categorical\", \"drop\", categorical_cols)\n",
    "                            )\n",
    "                        preprocessor = ColumnTransformer(\n",
    "                            transformers=transformers, remainder=\"passthrough\"\n",
    "                        )\n",
    "                        pipeline = Pipeline(\n",
    "                            steps=[\n",
    "                                (\"preprocessor\", preprocessor),\n",
    "                                (\"model\", config[\"models\"][\"instance\"]),\n",
    "                            ]\n",
    "                        )\n",
    "\n",
    "                        # Train the pipeline\n",
    "                        y_train_series = (\n",
    "                            y_train.compute().squeeze()\n",
    "                        )  # Convert to Pandas Series\n",
    "\n",
    "                        pipeline.fit(X_train.compute(), y_train_series)\n",
    "\n",
    "                        # Predictions and probabilities for train and test sets\n",
    "                        train_predictions = pipeline.predict(X_train.compute())\n",
    "                        train_probabilities = pipeline.predict_proba(X_train.compute())[\n",
    "                            :, 1\n",
    "                        ]\n",
    "                        start_time = time.time()\n",
    "                        test_predictions = pipeline.predict(X_test.compute())\n",
    "                        test_probabilities = pipeline.predict_proba(X_test.compute())[\n",
    "                            :, 1\n",
    "                        ]\n",
    "                        total_time += time.time() - start_time\n",
    "                        average_time = total_time / len(X_test)\n",
    "\n",
    "                        # Evaluate metrics\n",
    "                        metrics = self.evaluate_metrics(\n",
    "                            y_train.compute(),\n",
    "                            train_predictions,\n",
    "                            train_probabilities,\n",
    "                            y_test.compute(),\n",
    "                            test_predictions,\n",
    "                            test_probabilities,\n",
    "                        )\n",
    "\n",
    "                        # Log parameters, metrics, and model\n",
    "                        mlflow.log_params(config)\n",
    "                        mlflow.log_metrics(metrics)\n",
    "                        mlflow.sklearn.log_model(\n",
    "                            pipeline, \"model\", input_example=X_train.compute().iloc[0:1]\n",
    "                        )\n",
    "                        mlflow.log_metric(\"average_prediction_time\", average_time)\n",
    "\n",
    "                        # Save learning curves\n",
    "                        learning_curve_path = self.plot_learning_curves(\n",
    "                            pipeline, X_train.compute(), y_train.compute()\n",
    "                        )\n",
    "                        mlflow.log_artifact(\n",
    "                            learning_curve_path, artifact_path=\"learning_curves\"\n",
    "                        )\n",
    "\n",
    "                        # Mark this run as completed\n",
    "                        self.completed_runs.add(run_id)\n",
    "                        self.save_checkpoint()\n",
    "                        print(f\"Completed run: {run_id}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in run {run_id}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "                finally:\n",
    "                    print(\"end run\")\n",
    "                    mlflow.end_run()  # Ensure the run is properly ended\n",
    "\n",
    "            client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Create the different datasets to be used later`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "X_train = dd.read_csv(\"./data/X_train.csv\")\n",
    "y_train = dd.read_csv(\"./data/y_train.csv\")\n",
    "\n",
    "X_test = dd.read_csv(\"./data/X_test.csv\")\n",
    "y_test = dd.read_csv(\"./data/y_test.csv\")\n",
    "\n",
    "X_train_ISO = dd.read_csv(\"./data/X_train_ISO.csv\")\n",
    "y_train_ISO = dd.read_csv(\"./data/y_train_ISO.csv\")\n",
    "\n",
    "X_train_ISO_SMOTE = dd.read_csv(\"./data/X_train_ISO_smote.csv\")\n",
    "y_train_ISO_SMOTE = dd.read_csv(\"./data/y_train_ISO_smote.csv\")\n",
    "\n",
    "X_train_ISO_ROS = dd.read_csv(\"./data/X_train_ISO_ros.csv\")\n",
    "y_train_ISO_ROS = dd.read_csv(\"./data/y_train_ISO_ros.csv\")\n",
    "\n",
    "X_train_ISO_RUS = dd.read_csv(\"./data/X_train_ISO_rus.csv\")\n",
    "y_train_ISO_RUS = dd.read_csv(\"./data/y_train_ISO_rus.csv\")\n",
    "\n",
    "X_train_LOF = dd.read_csv(\"./data/X_train_LOF.csv\")\n",
    "y_train_LOF = dd.read_csv(\"./data/y_train_LOF.csv\")\n",
    "\n",
    "X_train_LOF_SMOTE = dd.read_csv(\"./data/X_train_LOF_smote.csv\")\n",
    "y_train_LOF_SMOTE = dd.read_csv(\"./data/y_train_LOF_smote.csv\")\n",
    "\n",
    "X_train_LOF_ROS = dd.read_csv(\"./data/X_train_LOF_ros.csv\")\n",
    "y_train_LOF_ROS = dd.read_csv(\"./data/y_train_LOF_ros.csv\")\n",
    "\n",
    "X_train_LOF_RUS = dd.read_csv(\"./data/X_train_LOF_rus.csv\")\n",
    "y_train_LOF_RUS = dd.read_csv(\"./data/y_train_LOF_rus.csv\")\n",
    "\n",
    "X_train_smote = dd.read_csv(\"./data/X_train_smote.csv\")\n",
    "y_train_smote = dd.read_csv(\"./data/y_train_smote.csv\")\n",
    "\n",
    "X_train_ros = dd.read_csv(\"./data/X_train_ros.csv\")\n",
    "y_train_ros = dd.read_csv(\"./data/y_train_ros.csv\")\n",
    "\n",
    "X_train_rus = dd.read_csv(\"./data/X_train_rus.csv\")\n",
    "y_train_rus = dd.read_csv(\"./data/y_train_rus.csv\")\n",
    "\n",
    "datasets = [\n",
    "    (\"dataset_default\", X_train, y_train),\n",
    "    (\"dataset_ISO\", X_train_ISO, y_train_ISO),\n",
    "    (\"dataset_ISO_SMOTE\", X_train_ISO_SMOTE, y_train_ISO_SMOTE),\n",
    "    (\"dataset_ISO_ROS\", X_train_ISO_ROS, y_train_ISO_ROS),\n",
    "    (\"dataset_ISO_RUS\", X_train_ISO_RUS, y_train_ISO_RUS),\n",
    "    (\"dataset_LOF\", X_train_LOF, y_train_LOF),\n",
    "    (\"dataset_LOF_SMOTE\", X_train_LOF_SMOTE, y_train_LOF_SMOTE),\n",
    "    (\"dataset_LOF_ROS\", X_train_LOF_ROS, y_train_LOF_ROS),\n",
    "    (\"dataset_LOF_RUS\", X_train_LOF_RUS, y_train_LOF_RUS),\n",
    "    (\"dataset_SMOTE\", X_train_smote, y_train_smote),\n",
    "    (\"dataset_ROS\", X_train_ros, y_train_ros),\n",
    "    (\"dataset_RUS\", X_train_rus, y_train_rus),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Defining Search Space for Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment configurations\n",
    "search_space = {\n",
    "    \"scaler\": [None],\n",
    "    \"encode\": [{\"apply\": True, \"columns\": [\"categorical_col\"]}],\n",
    "    \"models\": [\n",
    "        {\"name\": \"LogisticRegression\", \"instance\": LogisticRegression()},\n",
    "        {\"name\": \"RandomForest\", \"instance\": RandomForestClassifier()},\n",
    "        {\"name\": \"LightGBM\", \"instance\": LGBMClassifier()},\n",
    "        {\"name\": \"GaussianNB\", \"instance\": GaussianNB()},\n",
    "        {\"name\": \"DecisionTree\", \"instance\": DecisionTreeClassifier()},\n",
    "        {\"name\": \"GradientBoosting\", \"instance\": GradientBoostingClassifier()},\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Generate all combinations\n",
    "keys, values = zip(*search_space.items())\n",
    "experiment_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "categorical_cols = [\"payment_method\", \"country_code\", \"collect_type\"]\n",
    "numeric_columns = [\n",
    "    \"order_value\",\n",
    "    \"refund_value\",\n",
    "    \"num_items_ordered\",\n",
    "    \"days_since_first_order\",\n",
    "    \"order_date_day_of_week\",\n",
    "    \"order_date_day\",\n",
    "    \"order_date_month\",\n",
    "    \"order_date_year\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tracker\n",
    "from ExperimentTracker2 import PhaseTwoExperimentTracker\n",
    "tracker = PhaseTwoExperimentTracker(\"Phase2\")\n",
    "\n",
    "# Load checkpoint file\n",
    "tracker.completed_runs\n",
    "\n",
    "# Run experiments with checkpointing\n",
    "tracker.run_experiments(\n",
    "    datasets=datasets,\n",
    "    experiment_combinations=experiment_combinations,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    numeric_columns=numeric_columns,\n",
    "    categorical_cols=categorical_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Results`: The two best type of models are RandomForests and LightGBM, with the resampling method and outlier handling method being ROS and LOF for RandomForests and No resampling and LOF for LightGBM. Next we will combine the best preprocessing steps and test the models again.\n",
    "\n",
    "<img class=\"text-center\" src=\"images/results/phase2.png\" width=\"1500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Phase 3`: We will test the best models from the previous phases with feature selection techniques (e.g., PCA, feature importance from tree-based models) and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`First Set of Models`: We will test the best models with the best preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseThreeExperimentTracker(BaseExperimentTracker):\n",
    "    def run_experiments(\n",
    "        self,\n",
    "        datasets,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        experiment_combinations,\n",
    "        numeric_columns,\n",
    "        categorical_cols,\n",
    "    ):\n",
    "        \"\"\"Run experiments for Phase 2 on multiple datasets.\"\"\"\n",
    "        client = Client()  # Initialize Dask client for parallel processing\n",
    "        total_time = 0\n",
    "        for dataset_name, X_train, y_train in datasets:\n",
    "            for config in experiment_combinations:\n",
    "                if (\n",
    "                    dataset_name == \"dataset_LOF_ROS\"\n",
    "                    and config[\"models\"] == \"RandomForest\"\n",
    "                ) or (dataset_name == \"dataset_LOF\" and config[\"models\"] == \"LightGBM\"):\n",
    "                    run_id = self.generate_run_id(config)\n",
    "                    if run_id in self.completed_runs:\n",
    "                        print(f\"Skipping completed run: {run_id}\")\n",
    "                        continue\n",
    "                    print(f\"Starting run: {run_id}\")\n",
    "                    try:\n",
    "                        with mlflow.start_run(run_name=run_id):\n",
    "                            # Add descriptive run tags\n",
    "                            mlflow.set_tag(\"dataset\", dataset_name)\n",
    "                            mlflow.set_tag(\"model_type\", config[\"models\"][\"name\"])\n",
    "                            mlflow.set_tag(\n",
    "                                \"scaler_type\", config[\"scaler\"].__class__.__name__\n",
    "                            )\n",
    "                            mlflow.set_tag(\n",
    "                                \"encoding_applied\", str(config[\"encode\"][\"apply\"])\n",
    "                            )\n",
    "\n",
    "                            # Split dataset name\n",
    "                            dataset_names = dataset_name.split(\"_\")\n",
    "                            mlflow.set_tag(\n",
    "                                \"outlier_technique\",\n",
    "                                (\n",
    "                                    \"LOF\"\n",
    "                                    if \"LOF\" in dataset_names\n",
    "                                    else \"ISO\" if \"ISO\" in dataset_names else \"None\"\n",
    "                                ),\n",
    "                            )\n",
    "                            mlflow.set_tag(\n",
    "                                \"resampling_method\",\n",
    "                                (\n",
    "                                    \"SMOTE\"\n",
    "                                    if \"SMOTE\" in dataset_names\n",
    "                                    else (\n",
    "                                        \"ROS\"\n",
    "                                        if \"ROS\" in dataset_names\n",
    "                                        else \"RUS\" if \"RUS\" in dataset_names else \"None\"\n",
    "                                    )\n",
    "                                ),\n",
    "                            )\n",
    "\n",
    "                            # Build preprocessing steps\n",
    "                            transformers = []\n",
    "                            if config[\"scaler\"]:\n",
    "                                transformers.append(\n",
    "                                    (\"scaler\", config[\"scaler\"], numeric_columns)\n",
    "                                )\n",
    "                            if config[\"encode\"][\"apply\"]:\n",
    "                                transformers.append(\n",
    "                                    (\n",
    "                                        \"encoder\",\n",
    "                                        OneHotEncoder(\n",
    "                                            handle_unknown=\"ignore\", sparse_output=True\n",
    "                                        ),\n",
    "                                        categorical_cols,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                transformers.append(\n",
    "                                    (\"drop_categorical\", \"drop\", categorical_cols)\n",
    "                                )\n",
    "                            preprocessor = ColumnTransformer(\n",
    "                                transformers=transformers, remainder=\"passthrough\"\n",
    "                            )\n",
    "                            pipeline = Pipeline(\n",
    "                                steps=[\n",
    "                                    (\"preprocessor\", preprocessor),\n",
    "                                    (\"model\", config[\"models\"][\"instance\"]),\n",
    "                                ]\n",
    "                            )\n",
    "\n",
    "                            # Train the pipeline\n",
    "                            y_train_series = (\n",
    "                                y_train.compute().squeeze()\n",
    "                            )  # Convert to Pandas Series\n",
    "\n",
    "                            pipeline.fit(X_train.compute(), y_train_series)\n",
    "\n",
    "                            # Predictions and probabilities for train and test sets\n",
    "                            train_predictions = pipeline.predict(X_train.compute())\n",
    "                            train_probabilities = pipeline.predict_proba(\n",
    "                                X_train.compute()\n",
    "                            )[:, 1]\n",
    "                            start_time = time.time()\n",
    "                            test_predictions = pipeline.predict(X_test.compute())\n",
    "                            test_probabilities = pipeline.predict_proba(\n",
    "                                X_test.compute()\n",
    "                            )[:, 1]\n",
    "                            total_time += time.time() - start_time\n",
    "                            average_time = total_time / len(X_test)\n",
    "\n",
    "                            # Evaluate metrics\n",
    "                            metrics = self.evaluate_metrics(\n",
    "                                y_train.compute(),\n",
    "                                train_predictions,\n",
    "                                train_probabilities,\n",
    "                                y_test.compute(),\n",
    "                                test_predictions,\n",
    "                                test_probabilities,\n",
    "                            )\n",
    "\n",
    "                            # Log parameters, metrics, and model\n",
    "                            mlflow.log_params(config)\n",
    "                            mlflow.log_metrics(metrics)\n",
    "                            mlflow.sklearn.log_model(\n",
    "                                pipeline,\n",
    "                                \"model\",\n",
    "                                input_example=X_train.compute().iloc[0:1],\n",
    "                            )\n",
    "                            mlflow.log_metric(\"average_prediction_time\", average_time)\n",
    "\n",
    "                            # Save learning curves\n",
    "                            learning_curve_path = self.plot_learning_curves(\n",
    "                                pipeline, X_train.compute(), y_train.compute()\n",
    "                            )\n",
    "                            mlflow.log_artifact(\n",
    "                                learning_curve_path, artifact_path=\"learning_curves\"\n",
    "                            )\n",
    "\n",
    "                            # Mark this run as completed\n",
    "                            self.completed_runs.add(run_id)\n",
    "                            self.save_checkpoint()\n",
    "                            print(f\"Completed run: {run_id}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in run {run_id}: {str(e)}\")\n",
    "                        continue\n",
    "\n",
    "                    finally:\n",
    "                        print(\"end run\")\n",
    "                        mlflow.end_run()  # Ensure the run is properly ended\n",
    "\n",
    "            client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Filter the datasets to only include the best outliers and resampling methods`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    # (\"dataset_default\", X_train, y_train),\n",
    "    # (\"dataset_ISO\", X_train_ISO, y_train_ISO),\n",
    "    # (\"dataset_ISO_SMOTE\", X_train_ISO_SMOTE, y_train_ISO_SMOTE),\n",
    "    # (\"dataset_ISO_ROS\", X_train_ISO_ROS, y_train_ISO_ROS),\n",
    "    # (\"dataset_ISO_RUS\", X_train_ISO_RUS, y_train_ISO_RUS),\n",
    "    (\"dataset_LOF\", X_train_LOF, y_train_LOF),\n",
    "    # (\"dataset_LOF_SMOTE\", X_train_LOF_SMOTE, y_train_LOF_SMOTE),\n",
    "    (\"dataset_LOF_ROS\", X_train_LOF_ROS, y_train_LOF_ROS),\n",
    "    # (\"dataset_LOF_RUS\", X_train_LOF_RUS, y_train_LOF_RUS),\n",
    "    # (\"dataset_SMOTE\", X_train_smote, y_train_smote),\n",
    "    # (\"dataset_ROS\", X_train_ros, y_train_ros),\n",
    "    # (\"dataset_RUS\", X_train_rus, y_train_rus)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Defining Search Space for Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_experiment_combinations = [\n",
    "    {\n",
    "        \"scaler\": MinMaxScaler(),\n",
    "        \"encode\": {\"apply\": True, \"columns\": [\"categorical_col\"]},\n",
    "        \"models\": {\"name\": \"RandomForest\", \"instance\": RandomForestClassifier()},\n",
    "    },\n",
    "    {\n",
    "        \"scaler\": None,\n",
    "        \"encode\": {\"apply\": True, \"columns\": [\"categorical_col\"]},\n",
    "        \"models\": {\"name\": \"RandomForest\", \"instance\": RandomForestClassifier()},\n",
    "    },\n",
    "    {\n",
    "        \"scaler\": StandardScaler(),\n",
    "        \"encode\": {\"apply\": True, \"columns\": [\"categorical_col\"]},\n",
    "        \"models\": {\"name\": \"LightGBM\", \"instance\": LGBMClassifier()},\n",
    "    },\n",
    "    {\n",
    "        \"scaler\": None,\n",
    "        \"encode\": {\"apply\": True, \"columns\": [\"categorical_col\"]},\n",
    "        \"models\": {\"name\": \"LightGBM\", \"instance\": LGBMClassifier()},\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExperimentTrackers2 import PhaseThreeExperimentTracker\n",
    "\n",
    "tracker = PhaseThreeExperimentTracker(\"Final Experiment\")\n",
    "\n",
    "# Load checkpoint file\n",
    "tracker.completed_runs\n",
    "\n",
    "# Run experiments with checkpointing\n",
    "tracker.run_experiments(\n",
    "    datasets=datasets,\n",
    "    experiment_combinations=defined_experiment_combinations,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    numeric_columns=numeric_columns,\n",
    "    categorical_cols=categorical_cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Second Set of Models`: We will apply feature selection techniques (e.g., PCA, feature importance from tree-based models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseFourExperimentTracker(BaseExperimentTracker):\n",
    "    def generate_run_id(self, config):\n",
    "        \"\"\"Generate a concise, unique identifier for a run configuration.\"\"\"\n",
    "        model_abbr = config[\"models\"][\"name\"][:2].upper()  # Abbreviate model name\n",
    "        scaler_abbr = config[\"scaler\"].__class__.__name__.replace(\n",
    "            \"Scaler\", \"\"\n",
    "        )  # Simplify scaler name\n",
    "        encoding_status = \"Enc\" if config[\"encode\"][\"apply\"] else \"NoEnc\"\n",
    "        timestamp = time.strftime(\"%Y%m%d%H%M\")  # Add timestamp for uniqueness\n",
    "        return f\"{model_abbr}_{scaler_abbr}_{encoding_status}_{timestamp}_reduced\"\n",
    "\n",
    "    def run_experiments(\n",
    "        self,\n",
    "        datasets,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        experiment_combinations,\n",
    "        numeric_columns,\n",
    "        categorical_cols,\n",
    "        drop_columns,\n",
    "    ):\n",
    "        \"\"\"Run experiments for Phase 4 on multiple datasets.\"\"\"\n",
    "        client = Client()  # Initialize Dask client for parallel processing\n",
    "        total_time = 0\n",
    "        for dataset_name, X_train, y_train in datasets:\n",
    "            if drop_columns:\n",
    "                X_train = X_train.drop(columns=drop_columns)\n",
    "                X_test = X_test.drop(columns=drop_columns)\n",
    "            for config in experiment_combinations:\n",
    "                if (\n",
    "                    dataset_name == \"dataset_LOS_ROF\"\n",
    "                    and config[\"models\"] == \"RandomForest\"\n",
    "                ) or (dataset_name == \"dataset_LOF\" and config[\"models\"] == \"LightGBM\"):\n",
    "                    run_id = self.generate_run_id(config)\n",
    "                    if run_id in self.completed_runs:\n",
    "                        print(f\"Skipping completed run: {run_id}\")\n",
    "                        continue\n",
    "                    print(f\"Starting run: {run_id}\")\n",
    "                    try:\n",
    "                        with mlflow.start_run(run_name=run_id):\n",
    "                            # Add descriptive run tags\n",
    "                            mlflow.set_tag(\"dataset\", dataset_name)\n",
    "                            mlflow.set_tag(\"model_type\", config[\"models\"][\"name\"])\n",
    "                            mlflow.set_tag(\n",
    "                                \"scaler_type\", config[\"scaler\"].__class__.__name__\n",
    "                            )\n",
    "                            mlflow.set_tag(\n",
    "                                \"encoding_applied\", str(config[\"encode\"][\"apply\"])\n",
    "                            )\n",
    "\n",
    "                            # Split dataset name\n",
    "                            dataset_names = dataset_name.split(\"_\")\n",
    "                            mlflow.set_tag(\n",
    "                                \"outlier_technique\",\n",
    "                                (\n",
    "                                    \"LOF\"\n",
    "                                    if \"LOF\" in dataset_names\n",
    "                                    else \"ISO\" if \"ISO\" in dataset_names else \"None\"\n",
    "                                ),\n",
    "                            )\n",
    "                            mlflow.set_tag(\n",
    "                                \"resampling_method\",\n",
    "                                (\n",
    "                                    \"SMOTE\"\n",
    "                                    if \"SMOTE\" in dataset_names\n",
    "                                    else (\n",
    "                                        \"ROS\"\n",
    "                                        if \"ROS\" in dataset_names\n",
    "                                        else \"RUS\" if \"RUS\" in dataset_names else \"None\"\n",
    "                                    )\n",
    "                                ),\n",
    "                            )\n",
    "\n",
    "                            # Build preprocessing steps\n",
    "                            transformers = []\n",
    "                            if config[\"scaler\"]:\n",
    "                                transformers.append(\n",
    "                                    (\"scaler\", config[\"scaler\"], numeric_columns)\n",
    "                                )\n",
    "                            if config[\"encode\"][\"apply\"]:\n",
    "                                transformers.append(\n",
    "                                    (\n",
    "                                        \"encoder\",\n",
    "                                        OneHotEncoder(\n",
    "                                            handle_unknown=\"ignore\", sparse_output=True\n",
    "                                        ),\n",
    "                                        categorical_cols,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                transformers.append(\n",
    "                                    (\"drop_categorical\", \"drop\", categorical_cols)\n",
    "                                )\n",
    "                            preprocessor = ColumnTransformer(\n",
    "                                transformers=transformers, remainder=\"passthrough\"\n",
    "                            )\n",
    "                            pipeline = Pipeline(\n",
    "                                steps=[\n",
    "                                    (\"preprocessor\", preprocessor),\n",
    "                                    (\"model\", config[\"models\"][\"instance\"]),\n",
    "                                ]\n",
    "                            )\n",
    "\n",
    "                            # Train the pipeline\n",
    "                            y_train_series = (\n",
    "                                y_train.compute().squeeze()\n",
    "                            )  # Convert to Pandas Series\n",
    "\n",
    "                            pipeline.fit(X_train.compute(), y_train_series)\n",
    "\n",
    "                            # Predictions and probabilities for train and test sets\n",
    "                            train_predictions = pipeline.predict(X_train.compute())\n",
    "                            train_probabilities = pipeline.predict_proba(\n",
    "                                X_train.compute()\n",
    "                            )[:, 1]\n",
    "                            start_time = time.time()\n",
    "                            test_predictions = pipeline.predict(X_test.compute())\n",
    "                            test_probabilities = pipeline.predict_proba(\n",
    "                                X_test.compute()\n",
    "                            )[:, 1]\n",
    "                            total_time += time.time() - start_time\n",
    "                            average_time = total_time / len(X_test)\n",
    "\n",
    "                            # Evaluate metrics\n",
    "                            metrics = self.evaluate_metrics(\n",
    "                                y_train.compute(),\n",
    "                                train_predictions,\n",
    "                                train_probabilities,\n",
    "                                y_test.compute(),\n",
    "                                test_predictions,\n",
    "                                test_probabilities,\n",
    "                            )\n",
    "\n",
    "                            # Log parameters, metrics, and model\n",
    "                            mlflow.log_params(config)\n",
    "                            mlflow.log_metrics(metrics)\n",
    "                            mlflow.sklearn.log_model(\n",
    "                                pipeline,\n",
    "                                \"model\",\n",
    "                                input_example=X_train.compute().iloc[0:1],\n",
    "                            )\n",
    "                            mlflow.log_metric(\"average_prediction_time\", average_time)\n",
    "\n",
    "                            # Save learning curves\n",
    "                            learning_curve_path = self.plot_learning_curves(\n",
    "                                pipeline, X_train.compute(), y_train.compute()\n",
    "                            )\n",
    "                            mlflow.log_artifact(\n",
    "                                learning_curve_path, artifact_path=\"learning_curves\"\n",
    "                            )\n",
    "\n",
    "                            # Mark this run as completed\n",
    "                            self.completed_runs.add(run_id)\n",
    "                            self.save_checkpoint()\n",
    "                            print(f\"Completed run: {run_id}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in run {run_id}: {str(e)}\")\n",
    "                        continue\n",
    "\n",
    "                    finally:\n",
    "                        print(\"end run\")\n",
    "                        mlflow.end_run()  # Ensure the run is properly ended\n",
    "\n",
    "            client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Defining Search Space for Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_experiment_combinations = [\n",
    "    {\n",
    "        \"scaler\": MinMaxScaler(),\n",
    "        \"encode\": {\"apply\": True, \"columns\": [\"categorical_col\"]},\n",
    "        \"models\": {\"name\": \"RandomForest\", \"instance\": RandomForestClassifier()},\n",
    "    },\n",
    "    {\n",
    "        \"scaler\": StandardScaler(),\n",
    "        \"encode\": {\"apply\": True, \"columns\": [\"categorical_col\"]},\n",
    "        \"models\": {\"name\": \"LightGBM\", \"instance\": LGBMClassifier()},\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExperimentTrackers2 import PhaseFourExperimentTracker\n",
    "\n",
    "tracker = PhaseFourExperimentTracker(\"Final Experiment\")\n",
    "\n",
    "# Load checkpoint file\n",
    "tracker.completed_runs\n",
    "\n",
    "categorical_cols_reduced = [\n",
    "    \"country_code\",\n",
    "]\n",
    "numeric_columns_reduced = [\n",
    "    \"order_value\",\n",
    "    \"refund_value\",\n",
    "    \"num_items_ordered\",\n",
    "    \"days_since_first_order\",\n",
    "    \"order_date_day_of_week\",\n",
    "    \"order_date_day\",\n",
    "    \"order_date_month\",\n",
    "    \"order_date_year\",\n",
    "]\n",
    "\n",
    "# Run experiments with checkpointing\n",
    "tracker.run_experiments(\n",
    "    datasets=datasets,\n",
    "    experiment_combinations=defined_experiment_combinations,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    numeric_columns=numeric_columns_reduced,\n",
    "    categorical_cols=categorical_cols_reduced,\n",
    "    drop_columns=[\"payment_method\", \"collect_type\", \"mobile_verified\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`For PCA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseFiveExperimentTracker(BaseExperimentTracker):\n",
    "    def generate_run_id(self, config):\n",
    "        \"\"\"Generate a concise, unique identifier for a run configuration.\"\"\"\n",
    "        model_abbr = config[\"models\"][\"name\"][:2].upper()  # Abbreviate model name\n",
    "        scaler_abbr = config[\"scaler\"].__class__.__name__.replace(\n",
    "            \"Scaler\", \"\"\n",
    "        )  # Simplify scaler name\n",
    "        encoding_status = \"Enc\" if config[\"encode\"][\"apply\"] else \"NoEnc\"\n",
    "        timestamp = time.strftime(\"%Y%m%d%H%M\")  # Add timestamp for uniqueness\n",
    "        return f\"{model_abbr}_{scaler_abbr}_{encoding_status}_{timestamp}_PCA\"\n",
    "\n",
    "    def run_experiments(\n",
    "        self,\n",
    "        datasets,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        experiment_combinations,\n",
    "        numeric_columns,\n",
    "        categorical_cols,\n",
    "        drop_columns,\n",
    "    ):\n",
    "        from sklearn.decomposition import PCA\n",
    "\n",
    "        client = Client(\n",
    "            dashboard_address=\":0\", local_directory=\"/tmp/dask-worker-space\"\n",
    "        )  # Initialize Dask client\n",
    "        total_time = 0\n",
    "        for dataset_name, X_train, y_train in datasets:\n",
    "\n",
    "            def safe_drop_columns(df, drop_columns):\n",
    "                \"\"\"Safely drop columns from a DataFrame if they exist.\"\"\"\n",
    "                valid_columns = [col for col in drop_columns if col in df.columns]\n",
    "                if valid_columns:\n",
    "                    return df.drop(columns=valid_columns)\n",
    "                return df\n",
    "\n",
    "            if drop_columns:\n",
    "                X_train = safe_drop_columns(X_train, drop_columns)\n",
    "                X_test = safe_drop_columns(X_test, drop_columns)\n",
    "\n",
    "            for config in experiment_combinations:\n",
    "                if (\n",
    "                    dataset_name == \"dataset_LOF_ROS\"\n",
    "                    and config[\"models\"][\"name\"] == \"RandomForest\"\n",
    "                ) or (\n",
    "                    dataset_name == \"dataset_LOF\"\n",
    "                    and config[\"models\"][\"name\"] == \"LightGBM\"\n",
    "                ):\n",
    "                    run_id = self.generate_run_id(config)\n",
    "                    if run_id in self.completed_runs:\n",
    "                        print(f\"Skipping completed run: {run_id}\")\n",
    "                        continue\n",
    "                    print(f\"Starting run: {run_id}\")\n",
    "                    try:\n",
    "                        with mlflow.start_run(run_name=run_id):\n",
    "                            # Add descriptive run tags\n",
    "                            mlflow.set_tag(\"dataset\", dataset_name)\n",
    "                            mlflow.set_tag(\"model_type\", config[\"models\"][\"name\"])\n",
    "                            mlflow.set_tag(\n",
    "                                \"scaler_type\", config[\"scaler\"].__class__.__name__\n",
    "                            )\n",
    "                            mlflow.set_tag(\n",
    "                                \"encoding_applied\", str(config[\"encode\"][\"apply\"])\n",
    "                            )\n",
    "                            print(config)\n",
    "                            mlflow.set_tag(\n",
    "                                \"pca_applied\", str(config[\"pca\"][\"apply\"])\n",
    "                            )  # New tag for PCA\n",
    "                            # Split dataset name\n",
    "                            dataset_names = dataset_name.split(\"_\")\n",
    "                            mlflow.set_tag(\n",
    "                                \"outlier_technique\",\n",
    "                                (\n",
    "                                    \"LOF\"\n",
    "                                    if \"LOF\" in dataset_names\n",
    "                                    else \"ISO\" if \"ISO\" in dataset_names else \"None\"\n",
    "                                ),\n",
    "                            )\n",
    "                            mlflow.set_tag(\n",
    "                                \"resampling_method\",\n",
    "                                (\n",
    "                                    \"SMOTE\"\n",
    "                                    if \"SMOTE\" in dataset_names\n",
    "                                    else (\n",
    "                                        \"ROS\"\n",
    "                                        if \"ROS\" in dataset_names\n",
    "                                        else \"RUS\" if \"RUS\" in dataset_names else \"None\"\n",
    "                                    )\n",
    "                                ),\n",
    "                            )\n",
    "                            # Build preprocessing steps\n",
    "                            transformers = []\n",
    "                            if config[\"scaler\"]:\n",
    "                                transformers.append(\n",
    "                                    (\"scaler\", config[\"scaler\"], numeric_columns)\n",
    "                                )\n",
    "                            if config[\"pca\"][\"apply\"]:\n",
    "                                pca = PCA(n_components=config[\"pca\"][\"n_components\"])\n",
    "                                transformers.append((\"pca\", pca, numeric_columns))\n",
    "                            if config[\"encode\"][\"apply\"]:\n",
    "                                transformers.append(\n",
    "                                    (\n",
    "                                        \"encoder\",\n",
    "                                        OneHotEncoder(\n",
    "                                            handle_unknown=\"ignore\", sparse_output=True\n",
    "                                        ),\n",
    "                                        categorical_cols,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                transformers.append(\n",
    "                                    (\"drop_categorical\", \"drop\", categorical_cols)\n",
    "                                )\n",
    "                            preprocessor = ColumnTransformer(\n",
    "                                transformers=transformers, remainder=\"passthrough\"\n",
    "                            )\n",
    "                            pipeline = Pipeline(\n",
    "                                steps=[\n",
    "                                    (\"preprocessor\", preprocessor),\n",
    "                                    (\"model\", config[\"models\"][\"instance\"]),\n",
    "                                ]\n",
    "                            )\n",
    "                            # Train the pipeline\n",
    "                            y_train_series = (\n",
    "                                y_train.compute().squeeze()\n",
    "                            )  # Convert to Pandas Series\n",
    "                            pipeline.fit(X_train.compute(), y_train_series)\n",
    "                            # Predictions and probabilities for train and test sets\n",
    "                            train_predictions = pipeline.predict(X_train.compute())\n",
    "                            train_probabilities = pipeline.predict_proba(\n",
    "                                X_train.compute()\n",
    "                            )[:, 1]\n",
    "                            start_time = time.time()\n",
    "                            test_predictions = pipeline.predict(X_test.compute())\n",
    "                            test_probabilities = pipeline.predict_proba(\n",
    "                                X_test.compute()\n",
    "                            )[:, 1]\n",
    "                            total_time += time.time() - start_time\n",
    "                            average_time = total_time / len(X_test)\n",
    "                            # Evaluate metrics\n",
    "                            metrics = self.evaluate_metrics(\n",
    "                                y_train.compute(),\n",
    "                                train_predictions,\n",
    "                                train_probabilities,\n",
    "                                y_test.compute(),\n",
    "                                test_predictions,\n",
    "                                test_probabilities,\n",
    "                            )\n",
    "                            # Log parameters, metrics, and model\n",
    "                            mlflow.log_params(config)\n",
    "                            mlflow.log_metrics(metrics)\n",
    "                            mlflow.sklearn.log_model(\n",
    "                                pipeline,\n",
    "                                \"model\",\n",
    "                                input_example=X_train.compute().iloc[0:1],\n",
    "                            )\n",
    "                            mlflow.log_metric(\"average_prediction_time\", average_time)\n",
    "                            # Save learning curves\n",
    "                            learning_curve_path = self.plot_learning_curves(\n",
    "                                pipeline, X_train.compute(), y_train.compute()\n",
    "                            )\n",
    "                            mlflow.log_artifact(\n",
    "                                learning_curve_path, artifact_path=\"learning_curves\"\n",
    "                            )\n",
    "                            # Mark this run as completed\n",
    "                            self.completed_runs.add(run_id)\n",
    "                            self.save_checkpoint()\n",
    "                            print(f\"Completed run: {run_id}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in run {run_id}: {str(e)}\")\n",
    "                        continue\n",
    "                    finally:\n",
    "                        print(\"end run\")\n",
    "                        mlflow.end_run()  # Ensure the run is properly ended\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Defining Search Space for Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_experiment_combinations = [\n",
    "    {\n",
    "        \"scaler\": MinMaxScaler(),\n",
    "        \"encode\": {\"apply\": True, \"columns\": [\"categorical_col\"]},\n",
    "        \"models\": {\"name\": \"RandomForest\", \"instance\": RandomForestClassifier()},\n",
    "        \"pca\": {\"apply\": True, \"n_components\": 0.95},\n",
    "    },\n",
    "    {\n",
    "        \"scaler\": StandardScaler(),\n",
    "        \"encode\": {\"apply\": True, \"columns\": [\"categorical_col\"]},\n",
    "        \"models\": {\"name\": \"LightGBM\", \"instance\": LGBMClassifier()},\n",
    "        \"pca\": {\"apply\": True, \"n_components\": 0.95},\n",
    "    },\n",
    "]\n",
    "\n",
    "categorical_cols_reduced = [\"country_code\"]\n",
    "numeric_columns_reduced = [\n",
    "    \"order_value\",\n",
    "    \"refund_value\",\n",
    "    \"num_items_ordered\",\n",
    "    \"days_since_first_order\",\n",
    "    \"order_date_day_of_week\",\n",
    "    \"order_date_day\",\n",
    "    \"order_date_month\",\n",
    "    \"order_date_year\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExperimentTracker2 import PhaseFiveExperimentTracker\n",
    "tracker = PhaseFiveExperimentTracker(\"Final Experiment\")\n",
    "\n",
    "# Load checkpoint file\n",
    "tracker.completed_runs\n",
    "\n",
    "# Run experiments with checkpointing\n",
    "tracker.run_experiments(\n",
    "    datasets=datasets,\n",
    "    experiment_combinations=defined_experiment_combinations,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    numeric_columns=numeric_columns_reduced,\n",
    "    categorical_cols=categorical_cols_reduced,\n",
    "    drop_columns=['payment_method', 'collect_type', 'mobile_verified']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Third Set of Models`: We will apply hyperparameter tuning to the best model.\n",
    "\n",
    "`Note`: As RandomForest and LightGBM have different hyperparameters, we will tune them separately. Hence we will run Phase Six two times, one for RandomForest and one for LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseSixExperimentTracker(BaseExperimentTracker):\n",
    "    def generate_run_id(self, config):\n",
    "        \"\"\"Generate a concise, unique identifier for a run configuration.\"\"\"\n",
    "        model_abbr = config[\"models\"][\"name\"][:2].upper()  # Abbreviate model name\n",
    "        scaler_abbr = config[\"scaler\"].__class__.__name__.replace(\n",
    "            \"Scaler\", \"\"\n",
    "        )  # Simplify scaler name\n",
    "        encoding_status = \"Enc\" if config[\"encode\"][\"apply\"] else \"NoEnc\"\n",
    "        timestamp = time.strftime(\"%Y%m%d%H%M\")  # Add timestamp for uniqueness\n",
    "        return f\"{model_abbr}_{scaler_abbr}_{encoding_status}_{timestamp}_hypertuned\"\n",
    "\n",
    "    def run_experiments(\n",
    "        self,\n",
    "        datasets,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        experiment_combinations,\n",
    "        numeric_columns,\n",
    "        categorical_cols,\n",
    "        drop_columns,\n",
    "        n_iter=10,\n",
    "    ):\n",
    "        \"\"\"Run experiments for Phase 4 on multiple datasets.\"\"\"\n",
    "        client = Client(\n",
    "            n_workers=6,\n",
    "            threads_per_worker=2,\n",
    "            memory_limit=\"4GB\",\n",
    "            local_directory=\"/tmp/dask-worker-space\",\n",
    "            dashboard_address=\":0\",\n",
    "        )\n",
    "        total_time = 0\n",
    "        for dataset_name, X_train, y_train in datasets:\n",
    "\n",
    "            def safe_drop_columns(df, drop_columns):\n",
    "                \"\"\"Safely drop columns from a DataFrame if they exist.\"\"\"\n",
    "                valid_columns = [col for col in drop_columns if col in df.columns]\n",
    "                if valid_columns:\n",
    "                    return df.drop(columns=valid_columns)\n",
    "                return df\n",
    "\n",
    "            if drop_columns:\n",
    "                X_train = safe_drop_columns(X_train, drop_columns)\n",
    "                X_test = safe_drop_columns(X_test, drop_columns)\n",
    "            for config in experiment_combinations:\n",
    "                if (\n",
    "                    dataset_name == \"dataset_LOF_ROS\"\n",
    "                    and config[\"models\"][\"name\"] == \"RandomForest\"\n",
    "                ) or (\n",
    "                    dataset_name == \"dataset_LOF\"\n",
    "                    and config[\"models\"][\"name\"] == \"LightGBM\"\n",
    "                ):\n",
    "                    run_id = self.generate_run_id(config)\n",
    "                    if run_id in self.completed_runs:\n",
    "                        print(f\"Skipping completed run: {run_id}\")\n",
    "                        continue\n",
    "                    print(f\"Starting run: {run_id}\")\n",
    "                    try:\n",
    "                        with mlflow.start_run(run_name=run_id):\n",
    "                            # Add descriptive run tags\n",
    "                            mlflow.set_tag(\"dataset\", dataset_name)\n",
    "                            mlflow.set_tag(\"model_type\", config[\"models\"][\"name\"])\n",
    "                            mlflow.set_tag(\n",
    "                                \"scaler_type\", config[\"scaler\"].__class__.__name__\n",
    "                            )\n",
    "                            mlflow.set_tag(\n",
    "                                \"encoding_applied\", str(config[\"encode\"][\"apply\"])\n",
    "                            )\n",
    "                            # Split dataset name\n",
    "                            dataset_names = dataset_name.split(\"_\")\n",
    "                            mlflow.set_tag(\n",
    "                                \"outlier_technique\",\n",
    "                                (\n",
    "                                    \"LOF\"\n",
    "                                    if \"LOF\" in dataset_names\n",
    "                                    else \"ISO\" if \"ISO\" in dataset_names else \"None\"\n",
    "                                ),\n",
    "                            )\n",
    "                            mlflow.set_tag(\n",
    "                                \"resampling_method\",\n",
    "                                (\n",
    "                                    \"SMOTE\"\n",
    "                                    if \"SMOTE\" in dataset_names\n",
    "                                    else (\n",
    "                                        \"ROS\"\n",
    "                                        if \"ROS\" in dataset_names\n",
    "                                        else \"RUS\" if \"RUS\" in dataset_names else \"None\"\n",
    "                                    )\n",
    "                                ),\n",
    "                            )\n",
    "                            # Build preprocessing steps\n",
    "                            transformers = []\n",
    "                            if config[\"scaler\"]:\n",
    "                                transformers.append(\n",
    "                                    (\"scaler\", config[\"scaler\"], numeric_columns)\n",
    "                                )\n",
    "                            if config[\"encode\"][\"apply\"]:\n",
    "                                transformers.append(\n",
    "                                    (\n",
    "                                        \"encoder\",\n",
    "                                        OneHotEncoder(\n",
    "                                            handle_unknown=\"ignore\", sparse_output=True\n",
    "                                        ),\n",
    "                                        categorical_cols,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                transformers.append(\n",
    "                                    (\"drop_categorical\", \"drop\", categorical_cols)\n",
    "                                )\n",
    "                            preprocessor = ColumnTransformer(\n",
    "                                transformers=transformers, remainder=\"passthrough\"\n",
    "                            )\n",
    "                            pipeline = Pipeline(\n",
    "                                steps=[\n",
    "                                    (\"preprocessor\", preprocessor),\n",
    "                                    (\"model\", config[\"models\"][\"instance\"]),\n",
    "                                ]\n",
    "                            )\n",
    "\n",
    "                            # Perform hyperparameter tuning\n",
    "                            param_distributions = config.get(\"params\", {})\n",
    "                            random_search = RandomizedSearchCV(\n",
    "                                pipeline,\n",
    "                                param_distributions=param_distributions,\n",
    "                                n_iter=n_iter,  # Number of parameter settings that are sampled\n",
    "                                cv=5,  # Number of cross-validation folds\n",
    "                                scoring=\"f1\",  # Scoring metric\n",
    "                                random_state=42,\n",
    "                            )\n",
    "\n",
    "                            # Train the pipeline with hyperparameter tuning\n",
    "                            y_train_series = (\n",
    "                                y_train.compute().squeeze()\n",
    "                            )  # Convert to Pandas Series\n",
    "                            random_search.fit(X_train.compute(), y_train_series)\n",
    "\n",
    "                            best_pipeline = random_search.best_estimator_\n",
    "\n",
    "                            # Predictions and probabilities for train and test sets\n",
    "                            train_predictions = best_pipeline.predict(X_train.compute())\n",
    "                            train_probabilities = best_pipeline.predict_proba(\n",
    "                                X_train.compute()\n",
    "                            )[:, 1]\n",
    "                            start_time = time.time()\n",
    "                            test_predictions = best_pipeline.predict(X_test.compute())\n",
    "                            test_probabilities = best_pipeline.predict_proba(\n",
    "                                X_test.compute()\n",
    "                            )[:, 1]\n",
    "                            total_time += time.time() - start_time\n",
    "                            average_time = total_time / len(X_test)\n",
    "\n",
    "                            # Evaluate metrics\n",
    "                            metrics = self.evaluate_metrics(\n",
    "                                y_train.compute(),\n",
    "                                train_predictions,\n",
    "                                train_probabilities,\n",
    "                                y_test.compute(),\n",
    "                                test_predictions,\n",
    "                                test_probabilities,\n",
    "                            )\n",
    "\n",
    "                            # Log parameters, metrics, and model\n",
    "                            mlflow.log_params(random_search.best_params_)\n",
    "                            mlflow.log_metrics(metrics)\n",
    "                            mlflow.sklearn.log_model(\n",
    "                                best_pipeline,\n",
    "                                \"model\",\n",
    "                                input_example=X_train.compute().iloc[0:1],\n",
    "                            )\n",
    "                            mlflow.log_metric(\"average_prediction_time\", average_time)\n",
    "\n",
    "                            # Save learning curves\n",
    "                            learning_curve_path = self.plot_learning_curves(\n",
    "                                best_pipeline, X_train.compute(), y_train.compute()\n",
    "                            )\n",
    "                            mlflow.log_artifact(\n",
    "                                learning_curve_path, artifact_path=\"learning_curves\"\n",
    "                            )\n",
    "\n",
    "                            # Mark this run as completed\n",
    "                            self.completed_runs.add(run_id)\n",
    "                            self.save_checkpoint()\n",
    "                            print(f\"Completed run: {run_id}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in run {run_id}: {str(e)}\")\n",
    "                        continue\n",
    "                    finally:\n",
    "                        print(\"end run\")\n",
    "                        mlflow.end_run()  # Ensure the run is properly ended\n",
    "            client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Defining Search Space for Training Random Forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_experiment_combinations = [\n",
    "    {\n",
    "        \"scaler\": MinMaxScaler(),\n",
    "        \"encode\": {\"apply\": True, \"columns\": [\"categorical_col\"]},\n",
    "        \"models\": {\"name\": \"RandomForest\", \"instance\": RandomForestClassifier()},\n",
    "        \"params\": {\n",
    "            \"model__n_estimators\": [100, 200, 300],\n",
    "            \"model__max_depth\": [10, 20, None],\n",
    "            \"model__min_samples_split\": [2, 5, 10],\n",
    "            \"model__min_samples_leaf\": [1, 2, 4],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "categorical_cols_reduced = [\"country_code\"]\n",
    "numeric_columns_reduced = [\n",
    "    \"order_value\",\n",
    "    \"refund_value\",\n",
    "    \"num_items_ordered\",\n",
    "    \"days_since_first_order\",\n",
    "    \"order_date_day_of_week\",\n",
    "    \"order_date_day\",\n",
    "    \"order_date_month\",\n",
    "    \"order_date_year\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Training Random Forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExperimentTracker2 import PhaseSixExperimentTracker\n",
    "tracker = PhaseSixExperimentTracker(\"Final Experiment\")\n",
    "\n",
    "tracker.completed_runs\n",
    "\n",
    "# Run experiments with checkpointing\n",
    "tracker.run_experiments(\n",
    "    datasets=datasets,\n",
    "    experiment_combinations=defined_experiment_combinations,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    numeric_columns=numeric_columns_reduced,\n",
    "    categorical_cols=categorical_cols_reduced,\n",
    "    drop_columns=['payment_method', 'collect_type', 'mobile_verified'],\n",
    "    n_iter=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseSevenExperimentTracker(BaseExperimentTracker):\n",
    "    def generate_run_id(self, config):\n",
    "        \"\"\"Generate a concise, unique identifier for a run configuration.\"\"\"\n",
    "        model_abbr = config[\"models\"][\"name\"][:2].upper()  # Abbreviate model name\n",
    "        scaler_abbr = config[\"scaler\"].__class__.__name__.replace(\n",
    "            \"Scaler\", \"\"\n",
    "        )  # Simplify scaler name\n",
    "        encoding_status = \"Enc\" if config[\"encode\"][\"apply\"] else \"NoEnc\"\n",
    "        timestamp = time.strftime(\"%Y%m%d%H%M\")  # Add timestamp for uniqueness\n",
    "        return f\"{model_abbr}_{scaler_abbr}_{encoding_status}_{timestamp}_hypertuned\"\n",
    "\n",
    "    def run_experiments(\n",
    "        self,\n",
    "        datasets,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        experiment_combinations,\n",
    "        numeric_columns,\n",
    "        categorical_cols,\n",
    "        n_iter=10,\n",
    "    ):\n",
    "        \"\"\"Run experiments for Phase 4 on multiple datasets.\"\"\"\n",
    "        client = Client(\n",
    "            n_workers=6,\n",
    "            threads_per_worker=2,\n",
    "            memory_limit=\"4GB\",\n",
    "            local_directory=\"/tmp/dask-worker-space\",\n",
    "            dashboard_address=\":0\",\n",
    "        )\n",
    "        total_time = 0\n",
    "        for dataset_name, X_train, y_train in datasets:\n",
    "            for config in experiment_combinations:\n",
    "                if (\n",
    "                    dataset_name == \"dataset_LOF_ROS\"\n",
    "                    and config[\"models\"][\"name\"] == \"RandomForest\"\n",
    "                ) or (\n",
    "                    dataset_name == \"dataset_LOF\"\n",
    "                    and config[\"models\"][\"name\"] == \"LightGBM\"\n",
    "                ):\n",
    "                    run_id = self.generate_run_id(config)\n",
    "                    if run_id in self.completed_runs:\n",
    "                        print(f\"Skipping completed run: {run_id}\")\n",
    "                        continue\n",
    "                    print(f\"Starting run: {run_id}\")\n",
    "                    try:\n",
    "                        with mlflow.start_run(run_name=run_id):\n",
    "                            # Add descriptive run tags\n",
    "                            mlflow.set_tag(\"dataset\", dataset_name)\n",
    "                            mlflow.set_tag(\"model_type\", config[\"models\"][\"name\"])\n",
    "                            mlflow.set_tag(\n",
    "                                \"scaler_type\", config[\"scaler\"].__class__.__name__\n",
    "                            )\n",
    "                            mlflow.set_tag(\n",
    "                                \"encoding_applied\", str(config[\"encode\"][\"apply\"])\n",
    "                            )\n",
    "                            # Split dataset name\n",
    "                            dataset_names = dataset_name.split(\"_\")\n",
    "                            mlflow.set_tag(\n",
    "                                \"outlier_technique\",\n",
    "                                (\n",
    "                                    \"LOF\"\n",
    "                                    if \"LOF\" in dataset_names\n",
    "                                    else \"ISO\" if \"ISO\" in dataset_names else \"None\"\n",
    "                                ),\n",
    "                            )\n",
    "                            mlflow.set_tag(\n",
    "                                \"resampling_method\",\n",
    "                                (\n",
    "                                    \"SMOTE\"\n",
    "                                    if \"SMOTE\" in dataset_names\n",
    "                                    else (\n",
    "                                        \"ROS\"\n",
    "                                        if \"ROS\" in dataset_names\n",
    "                                        else \"RUS\" if \"RUS\" in dataset_names else \"None\"\n",
    "                                    )\n",
    "                                ),\n",
    "                            )\n",
    "                            # Build preprocessing steps\n",
    "                            transformers = []\n",
    "                            if config[\"scaler\"]:\n",
    "                                transformers.append(\n",
    "                                    (\"scaler\", config[\"scaler\"], numeric_columns)\n",
    "                                )\n",
    "                            if config[\"encode\"][\"apply\"]:\n",
    "                                transformers.append(\n",
    "                                    (\n",
    "                                        \"encoder\",\n",
    "                                        OneHotEncoder(\n",
    "                                            handle_unknown=\"ignore\", sparse_output=True\n",
    "                                        ),\n",
    "                                        categorical_cols,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                transformers.append(\n",
    "                                    (\"drop_categorical\", \"drop\", categorical_cols)\n",
    "                                )\n",
    "                            preprocessor = ColumnTransformer(\n",
    "                                transformers=transformers, remainder=\"passthrough\"\n",
    "                            )\n",
    "                            pipeline = Pipeline(\n",
    "                                steps=[\n",
    "                                    (\"preprocessor\", preprocessor),\n",
    "                                    (\"model\", config[\"models\"][\"instance\"]),\n",
    "                                ]\n",
    "                            )\n",
    "\n",
    "                            # Perform hyperparameter tuning\n",
    "                            param_distributions = config.get(\"params\", {})\n",
    "                            random_search = RandomizedSearchCV(\n",
    "                                pipeline,\n",
    "                                param_distributions=param_distributions,\n",
    "                                n_iter=n_iter,  # Number of parameter settings that are sampled\n",
    "                                cv=5,  # Number of cross-validation folds\n",
    "                                scoring=\"f1\",  # Scoring metric\n",
    "                                random_state=42,\n",
    "                            )\n",
    "\n",
    "                            # Train the pipeline with hyperparameter tuning\n",
    "                            y_train_series = (\n",
    "                                y_train.compute().squeeze()\n",
    "                            )  # Convert to Pandas Series\n",
    "                            random_search.fit(X_train.compute(), y_train_series)\n",
    "\n",
    "                            best_pipeline = random_search.best_estimator_\n",
    "\n",
    "                            # Predictions and probabilities for train and test sets\n",
    "                            train_predictions = best_pipeline.predict(X_train.compute())\n",
    "                            train_probabilities = best_pipeline.predict_proba(\n",
    "                                X_train.compute()\n",
    "                            )[:, 1]\n",
    "                            start_time = time.time()\n",
    "                            test_predictions = best_pipeline.predict(X_test.compute())\n",
    "                            test_probabilities = best_pipeline.predict_proba(\n",
    "                                X_test.compute()\n",
    "                            )[:, 1]\n",
    "                            total_time += time.time() - start_time\n",
    "                            average_time = total_time / len(X_test)\n",
    "\n",
    "                            # Evaluate metrics\n",
    "                            metrics = self.evaluate_metrics(\n",
    "                                y_train.compute(),\n",
    "                                train_predictions,\n",
    "                                train_probabilities,\n",
    "                                y_test.compute(),\n",
    "                                test_predictions,\n",
    "                                test_probabilities,\n",
    "                            )\n",
    "\n",
    "                            # Log parameters, metrics, and model\n",
    "                            mlflow.log_params(random_search.best_params_)\n",
    "                            mlflow.log_metrics(metrics)\n",
    "                            mlflow.sklearn.log_model(\n",
    "                                best_pipeline,\n",
    "                                \"model\",\n",
    "                                input_example=X_train.compute().iloc[0:1],\n",
    "                            )\n",
    "                            mlflow.log_metric(\"average_prediction_time\", average_time)\n",
    "\n",
    "                            # Save learning curves\n",
    "                            learning_curve_path = self.plot_learning_curves(\n",
    "                                best_pipeline, X_train.compute(), y_train.compute()\n",
    "                            )\n",
    "                            mlflow.log_artifact(\n",
    "                                learning_curve_path, artifact_path=\"learning_curves\"\n",
    "                            )\n",
    "\n",
    "                            # Mark this run as completed\n",
    "                            self.completed_runs.add(run_id)\n",
    "                            self.save_checkpoint()\n",
    "                            print(f\"Completed run: {run_id}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error in run {run_id}: {str(e)}\")\n",
    "                        continue\n",
    "                    finally:\n",
    "                        print(\"end run\")\n",
    "                        mlflow.end_run()  # Ensure the run is properly ended\n",
    "            client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Defining Search Space for Training LightGBM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_experiment_combinations = [\n",
    "    {\n",
    "        \"scaler\": StandardScaler(),\n",
    "        \"encode\": {\"apply\": True, \"columns\": [\"categorical_col\"]},\n",
    "        \"models\": {\"name\": \"LightGBM\", \"instance\": LGBMClassifier()},\n",
    "        \"params\": {\n",
    "            \"learning_rate\": [0.01, 0.03, 0.05, 1],\n",
    "            \"max_depth\": [3, 5, 7, 10, -1],\n",
    "            \"min_samples_split\": [2, 5, 10, 20],\n",
    "            \"min_samples_leaf\": [1, 5, 10, 20],\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "categorical_cols = [\"payment_method\", \"country_code\", \"collect_type\"]\n",
    "numeric_columns = [\n",
    "    \"order_value\",\n",
    "    \"refund_value\",\n",
    "    \"num_items_ordered\",\n",
    "    \"days_since_first_order\",\n",
    "    \"order_date_day_of_week\",\n",
    "    \"order_date_day\",\n",
    "    \"order_date_month\",\n",
    "    \"order_date_year\",\n",
    "]\n",
    "\n",
    "# Update the datasets list with scattered futures\n",
    "datasets = [\n",
    "    (\"dataset_default\", X_train, y_train),\n",
    "    (\"dataset_LOF\", X_train_LOF, y_train_LOF),\n",
    "    (\"dataset_LOF_ROS\", X_train_LOF_ROS, y_train_LOF_ROS),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Training LightGBM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExperimentTracker2 import PhaseSevenExperimentTracker\n",
    "\n",
    "tracker = PhaseSevenExperimentTracker(\"Final Experiment\")\n",
    "\n",
    "tracker.completed_runs\n",
    "\n",
    "# Run experiments with checkpointing\n",
    "tracker.run_experiments(\n",
    "    datasets=datasets,\n",
    "    experiment_combinations=defined_experiment_combinations,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    numeric_columns=numeric_columns,\n",
    "    categorical_cols=categorical_cols,\n",
    "    n_iter=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Results`\n",
    "`First Set of Models`: We notice that adding the best scaler alongside the best resampling and outlier handling techniques improves the performance of the models. Hence we move forward with these models\n",
    "\n",
    "`Second Set of Models`: When applying feature selection, we notice that RandomForest performs better with feature selection, while LightGBM doesnt, hence we move ahead with RandomForest with feature selection and LightGBM without feature selection.\n",
    "\n",
    "`Third Set of Models`: When applying PCA, for RandomForest, the model with PCA performs worst than the model without PCA, hence we move ahead with RandomForest without PCA. For LightGBM, the model with PCA performs better than the model without PCA, however this difference is marginal and PCA could take longe to run and hence we move ahead with LightGBM without PCA.\n",
    "\n",
    "`Fourth Set of Models`: When applying hyperparameter tuning, we notice that both tuned RandomForest and LightGBM models perform worse than its untuned counterparts. However it actually helps with RandomForest overfitting. Hence, our best models are the tuned models.\n",
    "\n",
    "<img class=\"text-center\" src=\"images/results/finalexperiment.png\" width=\"1500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **4. Choosing Best Model**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing between the tuned RandomForest and LightGBM models, we notice that the RandomForest model performs better than the LightGBM model. Hence we will move forward with the RandomForest model.\n",
    "\n",
    "`Best Parameters for RandomForest`: {'n_estimators': 200, 'min_samples_split': 10, min_samples_leaf': 2, 'max_depth': None}\n",
    "\n",
    "`Learning Curve for RandomForest`:\n",
    "\n",
    "<img class=\"text-center\" src=\"images/final_model/curve.png\" width=\"1000\">\n",
    "\n",
    "`Observation`:\n",
    "The learning curve shows that the model is not overfitting or underfitting, as the training and validation curves converge and remain close to each other. This indicates that the model is generalizing well to unseen data. There is also leveling off of the validation curve, indicating that additional data may not significantly improve the model's performance. This suggests that the model has reached its optimal performance given the available data. In order to further improve the model's performance, we may need to consider other approaches in feature engineering or run grid search for hyper parameter tuning as we are currently using Random Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
