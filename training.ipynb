{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTENC, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import warnings\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import mlflow\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/merged_data.csv')\n",
    "\n",
    "merged_df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dtypes(df):\n",
    "    # Convert 'order_value' and 'refund_value' to float16 for memory efficiency\n",
    "    df['order_value'] = df['order_value'].astype('float32')\n",
    "    df['refund_value'] = df['refund_value'].astype('float32')\n",
    "    \n",
    "    # Convert 'num_items_ordered' to uint8 after rounding\n",
    "    df['num_items_ordered'] = df['num_items_ordered'].astype(float).round().astype('uint8')\n",
    "    \n",
    "    # Convert 'order_date' and 'first_order_datetime' to datetime\n",
    "    df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "    df['first_order_datetime'] = pd.to_datetime(df['first_order_datetime'])\n",
    "    \n",
    "    # Convert categorical columns to category dtype for efficiency\n",
    "    df[['country_code', 'collect_type', 'payment_method']] = df[['country_code', 'collect_type', 'payment_method']].astype('category')\n",
    "    \n",
    "    # Convert numerical columns (those that represent counts or numeric features) to uint16\n",
    "    df[['num_orders_last_50days', 'num_cancelled_orders_last_50days', 'num_refund_orders_last_50days']] = df[['num_orders_last_50days', 'num_cancelled_orders_last_50days', 'num_refund_orders_last_50days']].astype('uint16')\n",
    "    \n",
    "    # Convert 'num_associated_customers' to uint8 for efficient memory usage\n",
    "    df['num_associated_customers'] = df['num_associated_customers'].astype('uint8')\n",
    "    \n",
    "    # Convert 'total_payment_last_50days' to float16 for memory efficiency\n",
    "    df['total_payment_last_50days'] = df['total_payment_last_50days'].astype('float32')\n",
    "    \n",
    "    # Convert 'mobile_verified' and 'is_fraud' columns to boolean (mapping string values)\n",
    "    # df['mobile_verified'] = df['mobile_verified'].map({'True': True, 'False': False})\n",
    "    # df['is_fraud'] = df['is_fraud'].map({'1': True, '0': False})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_payment_methods(payment_method):\n",
    "    # Credit Card and Related Gateways\n",
    "    if payment_method in ['GenericCreditCard', 'CybersourceCreditCard', 'CybersourceApplePay', 'CreditCard']:\n",
    "        return 'CreditCard'\n",
    "    \n",
    "    # Digital Wallets\n",
    "    elif payment_method in ['GCash', 'AFbKash', 'JazzCashWallet', 'AFTrueMoney', 'AdyenBoost', 'AdyenMolpay',\n",
    "                            'AFTNG', 'AdyenHPPBoost', 'AdyenHPPMolpay', 'PayPal', 'AFGCash', 'AccountBalance']:\n",
    "        return 'DigitalWallet'\n",
    "    \n",
    "    # Bank Transfers and Direct Debit\n",
    "    elif payment_method in ['XenditDirectDebit', 'RazerOnlineBanking']:\n",
    "        return 'BankTransfer'\n",
    "    \n",
    "    # PayOnDelivery\n",
    "    elif payment_method in ['Invoice', 'PayOnDelivery']:\n",
    "        return 'PaymentOnDelivery'\n",
    "    \n",
    "    # Default case for unrecognized methods\n",
    "    else:\n",
    "        return 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_since_first_order(data, order_date_column, first_order_column):\n",
    "    # Create a feature for the number of days since the first order\n",
    "    data['days_since_first_order'] = (data[order_date_column] - data[first_order_column]).dt.days\n",
    "    data.drop([first_order_column], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def transform_datetime(data, column):\n",
    "    # Handle Datetime columns\n",
    "    data[column + '_day_of_week'] = data[column].dt.dayofweek\n",
    "    data[column + '_day'] = data[column].dt.day\n",
    "    data[column + '_month'] = data[column].dt.month\n",
    "    data[column + '_year'] = data[column].dt.year\n",
    "    data.drop([column], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def date_transformations(data):\n",
    "    data = days_since_first_order(data, 'order_date', 'first_order_datetime')\n",
    "    data = transform_datetime(data, 'order_date')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = convert_dtypes(merged_df)\n",
    "merged_df['payment_method'] = merged_df['payment_method'].apply(group_payment_methods)\n",
    "merged_df = date_transformations(merged_df)\n",
    "merged_df.drop(columns=['order_id', 'customer_id'], inplace=True)\n",
    "X=merged_df.drop(columns=['is_fraud'])\n",
    "y=merged_df['is_fraud']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ExperimentTrackers import PhaseOneExperimentTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "search_space = search_space = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler(), RobustScaler(), None],\n",
    "    'encode': [{'apply': True, 'columns': ['categorical_col']}, {'apply': False}],\n",
    "    'models': [\n",
    "        {'name': 'LogisticRegression', 'instance': LogisticRegression()},\n",
    "        {'name': 'RandomForest', 'instance': RandomForestClassifier()},\n",
    "        {'name': 'LightGBM', 'instance': LGBMClassifier()},\n",
    "        {'name': 'GaussianNB', 'instance': GaussianNB()},\n",
    "        {'name': 'DecisionTree', 'instance': DecisionTreeClassifier()},\n",
    "        {'name': 'GradientBoosting', 'instance': GradientBoostingClassifier()},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Generate all combinations of the search space\n",
    "keys, values = zip(*search_space.items())\n",
    "experiment_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "categorical_cols = ['payment_method', 'country_code', 'collect_type']\n",
    "numeric_columns = ['order_value', 'refund_value', 'num_items_ordered', 'num_orders_last_50days', 'num_cancelled_orders_last_50days', 'num_refund_orders_last_50days', 'num_associated_customers', 'total_payment_last_50days', 'days_since_first_order', 'order_date_day_of_week', 'order_date_day', 'order_date_month', 'order_date_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the tracker\n",
    "# tracker = PhaseOneExperimentTracker(\"Phase1.2\")\n",
    "\n",
    "# # Load checkpoint file\n",
    "# tracker.completed_runs\n",
    "\n",
    "# # Run experiments with checkpointing\n",
    "# tracker.run_experiments(\n",
    "#     experiment_combinations=experiment_combinations,\n",
    "#     X_train=X_train,\n",
    "#     y_train=y_train,\n",
    "#     X_test=X_test,\n",
    "#     y_test=y_test,\n",
    "#     numeric_columns=numeric_columns,\n",
    "#     categorical_cols=categorical_cols\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "X_train = pd.read_csv('./data/X_train.csv')\n",
    "y_train = pd.read_csv('./data/y_train.csv')\n",
    "\n",
    "X_test = pd.read_csv('./data/X_test.csv')\n",
    "y_test = pd.read_csv('./data/y_test.csv')\n",
    "\n",
    "X_train_ISO = pd.read_csv('./data/X_train_ISO.csv')\n",
    "y_train_ISO = pd.read_csv('./data/y_train_ISO.csv')\n",
    "\n",
    "X_train_ISO_SMOTE = pd.read_csv('./data/X_train_ISO_smote.csv')\n",
    "y_train_ISO_SMOTE = pd.read_csv('./data/y_train_ISO_smote.csv')\n",
    "\n",
    "X_train_ISO_ROS = pd.read_csv('./data/X_train_ISO_ros.csv')\n",
    "y_train_ISO_ROS = pd.read_csv('./data/y_train_ISO_ros.csv')\n",
    "\n",
    "X_train_ISO_RUS = pd.read_csv('./data/X_train_ISO_rus.csv')\n",
    "y_train_ISO_RUS = pd.read_csv('./data/y_train_ISO_rus.csv')\n",
    "\n",
    "X_train_LOF = pd.read_csv('./data/X_train_LOF.csv')\n",
    "y_train_LOF = pd.read_csv('./data/y_train_LOF.csv')\n",
    "\n",
    "X_train_LOF_SMOTE = pd.read_csv('./data/X_train_LOF_smote.csv')\n",
    "y_train_LOF_SMOTE = pd.read_csv('./data/y_train_LOF_smote.csv')\n",
    "\n",
    "X_train_LOF_ROS = pd.read_csv('./data/X_train_LOF_ros.csv')\n",
    "y_train_LOF_ROS = pd.read_csv('./data/y_train_LOF_ros.csv')\n",
    "\n",
    "X_train_LOF_RUS = pd.read_csv('./data/X_train_LOF_rus.csv')\n",
    "y_train_LOF_RUS = pd.read_csv('./data/y_train_LOF_rus.csv')\n",
    "\n",
    "X_train_smote = pd.read_csv('./data/X_train_smote.csv')\n",
    "y_train_smote = pd.read_csv('./data/y_train_smote.csv')\n",
    "\n",
    "X_train_ros = pd.read_csv('./data/X_train_ros.csv')\n",
    "y_train_ros = pd.read_csv('./data/y_train_ros.csv')\n",
    "\n",
    "X_train_rus = pd.read_csv('./data/X_train_rus.csv')\n",
    "y_train_rus = pd.read_csv('./data/y_train_rus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (\"dataset_default\", X_train, y_train),\n",
    "    (\"dataset_ISO\", X_train_ISO, y_train_ISO),\n",
    "    (\"dataset_ISO_SMOTE\", X_train_ISO_SMOTE, y_train_ISO_SMOTE),\n",
    "    (\"dataset_ISO_ROS\", X_train_ISO_ROS, y_train_ISO_ROS),\n",
    "    (\"dataset_ISO_RUS\", X_train_ISO_RUS, y_train_ISO_RUS),\n",
    "    (\"dataset_LOF\", X_train_LOF, y_train_LOF),\n",
    "    (\"dataset_LOF_SMOTE\", X_train_LOF_SMOTE, y_train_LOF_SMOTE),\n",
    "    (\"dataset_LOF_ROS\", X_train_LOF_ROS, y_train_LOF_ROS),\n",
    "    (\"dataset_LOF_RUS\", X_train_LOF_RUS, y_train_LOF_RUS),\n",
    "    (\"dataset_SMOTE\", X_train_smote, y_train_smote),\n",
    "    (\"dataset_ROS\", X_train_ros, y_train_ros),\n",
    "    (\"dataset_RUS\", X_train_rus, y_train_rus)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "search_space = {\n",
    "    'scaler': [None],\n",
    "    'encode': [{'apply': True, 'columns': ['categorical_col']}],\n",
    "    'models': [\n",
    "        {'name': 'LogisticRegression', 'instance': LogisticRegression()},\n",
    "        {'name': 'RandomForest', 'instance': RandomForestClassifier()},\n",
    "        {'name': 'LightGBM', 'instance': LGBMClassifier()},\n",
    "        {'name': 'GaussianNB', 'instance': GaussianNB()},\n",
    "        {'name': 'DecisionTree', 'instance': DecisionTreeClassifier()},\n",
    "        {'name': 'GradientBoosting', 'instance': GradientBoostingClassifier()},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Generate all combinations of the search space\n",
    "keys, values = zip(*search_space.items())\n",
    "experiment_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "categorical_cols = ['payment_method', 'country_code', 'collect_type']\n",
    "numeric_columns = ['order_value', 'refund_value', 'num_items_ordered', 'num_orders_last_50days', 'num_cancelled_orders_last_50days', 'num_refund_orders_last_50days', 'num_associated_customers', 'total_payment_last_50days', 'days_since_first_order', 'order_date_day_of_week', 'order_date_day', 'order_date_month', 'order_date_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run: LO_NoneType_Enc_20250209_0257\n",
      "Completed run: LO_NoneType_Enc_20250209_0257\n",
      "🏃 View run LO_NoneType_Enc_20250209_0257 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/c075b9b709b945c594cf73e4b6339162\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: RA_NoneType_Enc_20250209_0301\n",
      "Completed run: RA_NoneType_Enc_20250209_0301\n",
      "🏃 View run RA_NoneType_Enc_20250209_0301 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/0d65766b4aa140bca86fae383da0e89d\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: LI_NoneType_Enc_20250209_0327\n",
      "[LightGBM] [Info] Number of positive: 199486, number of negative: 1611458\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1744\n",
      "[LightGBM] [Info] Number of data points in the train set: 1810944, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110156 -> initscore=-2.089151\n",
      "[LightGBM] [Info] Start training from score -2.089151\n",
      "Completed run: LI_NoneType_Enc_20250209_0327\n",
      "🏃 View run LI_NoneType_Enc_20250209_0327 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/b4269e28c3054ec0b45a03fbc21c0caf\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: GA_NoneType_Enc_20250209_0329\n",
      "Completed run: GA_NoneType_Enc_20250209_0329\n",
      "🏃 View run GA_NoneType_Enc_20250209_0329 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/aa0506025a084a7fb84327954470490b\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: DE_NoneType_Enc_20250209_0331\n",
      "Completed run: DE_NoneType_Enc_20250209_0331\n",
      "🏃 View run DE_NoneType_Enc_20250209_0331 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/e6a6b09c04f146b0afc064eeb9f8f92e\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: GR_NoneType_Enc_20250209_0333\n",
      "Completed run: GR_NoneType_Enc_20250209_0333\n",
      "🏃 View run GR_NoneType_Enc_20250209_0333 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/42a7497b12994c9396299a6e09abf71a\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: LO_NoneType_Enc_20250209_0416\n",
      "Completed run: LO_NoneType_Enc_20250209_0416\n",
      "🏃 View run LO_NoneType_Enc_20250209_0416 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/ee6a52778ae1495f92ad4cc28a5cfcc0\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: RA_NoneType_Enc_20250209_0419\n",
      "Completed run: RA_NoneType_Enc_20250209_0419\n",
      "🏃 View run RA_NoneType_Enc_20250209_0419 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/45ad8085060246828b55ee8ea33b78d2\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: LI_NoneType_Enc_20250209_0443\n",
      "[LightGBM] [Info] Number of positive: 165970, number of negative: 1463879\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1500\n",
      "[LightGBM] [Info] Number of data points in the train set: 1629849, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101832 -> initscore=-2.177038\n",
      "[LightGBM] [Info] Start training from score -2.177038\n",
      "Completed run: LI_NoneType_Enc_20250209_0443\n",
      "🏃 View run LI_NoneType_Enc_20250209_0443 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/ecedc4ef66f24ff89a05e28ce58fc2c5\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: GA_NoneType_Enc_20250209_0446\n",
      "Completed run: GA_NoneType_Enc_20250209_0446\n",
      "🏃 View run GA_NoneType_Enc_20250209_0446 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/9f071cc1c49941989bcac69ef5c8e65c\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: DE_NoneType_Enc_20250209_0447\n",
      "Completed run: DE_NoneType_Enc_20250209_0447\n",
      "🏃 View run DE_NoneType_Enc_20250209_0447 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/1f4f9e78ae4849c1b13aac11775ca60b\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: GR_NoneType_Enc_20250209_0449\n",
      "Completed run: GR_NoneType_Enc_20250209_0449\n",
      "🏃 View run GR_NoneType_Enc_20250209_0449 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/15a634d2a21e43219a520b6599e6331f\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: LO_NoneType_Enc_20250209_0527\n",
      "Completed run: LO_NoneType_Enc_20250209_0527\n",
      "🏃 View run LO_NoneType_Enc_20250209_0527 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/63802f51a9834f1f9798ea3b9f89f2bb\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: RA_NoneType_Enc_20250209_0533\n",
      "Completed run: RA_NoneType_Enc_20250209_0533\n",
      "🏃 View run RA_NoneType_Enc_20250209_0533 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/1ea3fc046505406eb10597b8da21bccb\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: LI_NoneType_Enc_20250209_0626\n",
      "[LightGBM] [Info] Number of positive: 1463879, number of negative: 1463879\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.143931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1516\n",
      "[LightGBM] [Info] Number of data points in the train set: 2927758, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Completed run: LI_NoneType_Enc_20250209_0626\n",
      "🏃 View run LI_NoneType_Enc_20250209_0626 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/0a17562fb6fa458fb4509ab5982fc30d\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: GA_NoneType_Enc_20250209_0631\n",
      "Completed run: GA_NoneType_Enc_20250209_0631\n",
      "🏃 View run GA_NoneType_Enc_20250209_0631 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/0d36cce3c6c04e7ea97c689f955d48ae\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: DE_NoneType_Enc_20250209_0633\n",
      "Completed run: DE_NoneType_Enc_20250209_0633\n",
      "🏃 View run DE_NoneType_Enc_20250209_0633 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/e918f62d46ed4eb9a55ab77eb10e4586\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: GR_NoneType_Enc_20250209_0637\n",
      "Completed run: GR_NoneType_Enc_20250209_0637\n",
      "🏃 View run GR_NoneType_Enc_20250209_0637 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/5a9596ad74d94225abc138c29a368c35\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: LO_NoneType_Enc_20250209_0748\n",
      "Completed run: LO_NoneType_Enc_20250209_0748\n",
      "🏃 View run LO_NoneType_Enc_20250209_0748 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/9eb0dec5fbd9450f92a51a3e987904f1\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: RA_NoneType_Enc_20250209_0753\n",
      "Completed run: RA_NoneType_Enc_20250209_0753\n",
      "🏃 View run RA_NoneType_Enc_20250209_0753 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/e848e21866bd4888838185c17632e588\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: LI_NoneType_Enc_20250209_0837\n",
      "[LightGBM] [Info] Number of positive: 1463879, number of negative: 1463879\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.163652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 2927758, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Completed run: LI_NoneType_Enc_20250209_0837\n",
      "🏃 View run LI_NoneType_Enc_20250209_0837 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/c0cbc53393014677b1dc4a161b27ebe8\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: GA_NoneType_Enc_20250209_0841\n",
      "Completed run: GA_NoneType_Enc_20250209_0841\n",
      "🏃 View run GA_NoneType_Enc_20250209_0841 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/949242e6d70d4b2185569ee76657b2da\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: DE_NoneType_Enc_20250209_0843\n",
      "Completed run: DE_NoneType_Enc_20250209_0843\n",
      "🏃 View run DE_NoneType_Enc_20250209_0843 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/f36b0160053b49d9a25643adfe35e107\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: GR_NoneType_Enc_20250209_0847\n",
      "Completed run: GR_NoneType_Enc_20250209_0847\n",
      "🏃 View run GR_NoneType_Enc_20250209_0847 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/51747a0f58034f26b46203407f418cb5\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: LO_NoneType_Enc_20250209_0954\n",
      "Completed run: LO_NoneType_Enc_20250209_0954\n",
      "🏃 View run LO_NoneType_Enc_20250209_0954 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/e3e662d100814903b28ec8320e9873ff\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: RA_NoneType_Enc_20250209_0955\n",
      "Completed run: RA_NoneType_Enc_20250209_0955\n",
      "🏃 View run RA_NoneType_Enc_20250209_0955 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/eb3ca38d95574e05b201bf89982ce6ff\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: LI_NoneType_Enc_20250209_0959\n",
      "[LightGBM] [Info] Number of positive: 165970, number of negative: 165970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1519\n",
      "[LightGBM] [Info] Number of data points in the train set: 331940, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Completed run: LI_NoneType_Enc_20250209_0959\n",
      "🏃 View run LI_NoneType_Enc_20250209_0959 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/94134d106081418fb003293e007bd8c2\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: GA_NoneType_Enc_20250209_0959\n",
      "Completed run: GA_NoneType_Enc_20250209_0959\n",
      "🏃 View run GA_NoneType_Enc_20250209_0959 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/25fde3a37c6a4899b1103b0a2cebf3b1\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: DE_NoneType_Enc_20250209_1000\n",
      "Completed run: DE_NoneType_Enc_20250209_1000\n",
      "🏃 View run DE_NoneType_Enc_20250209_1000 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/5b40bb4d734c4b428ca425a4827e037a\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: GR_NoneType_Enc_20250209_1000\n",
      "Completed run: GR_NoneType_Enc_20250209_1000\n",
      "🏃 View run GR_NoneType_Enc_20250209_1000 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/9d2c5ba2a082462c93ce001ba06675cd\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: LO_NoneType_Enc_20250209_1006\n",
      "Completed run: LO_NoneType_Enc_20250209_1006\n",
      "🏃 View run LO_NoneType_Enc_20250209_1006 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/2ecfbc479c28461e9992235719e442f7\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: RA_NoneType_Enc_20250209_1009\n",
      "Completed run: RA_NoneType_Enc_20250209_1009\n",
      "🏃 View run RA_NoneType_Enc_20250209_1009 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/0fca2ef4012643bf891b3c5449ae06a8\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: LI_NoneType_Enc_20250209_1032\n",
      "[LightGBM] [Info] Number of positive: 189201, number of negative: 1591701\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1703\n",
      "[LightGBM] [Info] Number of data points in the train set: 1780902, number of used features: 38\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.106239 -> initscore=-2.129749\n",
      "[LightGBM] [Info] Start training from score -2.129749\n",
      "Completed run: LI_NoneType_Enc_20250209_1032\n",
      "🏃 View run LI_NoneType_Enc_20250209_1032 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/f13d880965ad4ff88de0e1294d3faf6e\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: GA_NoneType_Enc_20250209_1035\n",
      "Completed run: GA_NoneType_Enc_20250209_1035\n",
      "🏃 View run GA_NoneType_Enc_20250209_1035 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/035d95f5db8d4bbabcc68ab7299d5968\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: DE_NoneType_Enc_20250209_1036\n",
      "Completed run: DE_NoneType_Enc_20250209_1036\n",
      "🏃 View run DE_NoneType_Enc_20250209_1036 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/9200907ffcbb454ab702318400abab93\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: GR_NoneType_Enc_20250209_1039\n",
      "Completed run: GR_NoneType_Enc_20250209_1039\n",
      "🏃 View run GR_NoneType_Enc_20250209_1039 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/7e9c8f9f681a45deaf8577eadff2063d\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: LO_NoneType_Enc_20250209_1119\n",
      "Completed run: LO_NoneType_Enc_20250209_1119\n",
      "🏃 View run LO_NoneType_Enc_20250209_1119 at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12/runs/48f97d8fb5384d52b7bfcd07f34395a0\n",
      "🧪 View experiment at: https://dagshub.com/REHXZ/PAI_CA2.mlflow/#/experiments/12\n",
      "Starting run: RA_NoneType_Enc_20250209_1124\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tracker\n",
    "from ExperimentTrackers import PhaseTwoExperimentTracker\n",
    "tracker = PhaseTwoExperimentTracker(\"Phase2.4\")\n",
    "\n",
    "# Load checkpoint file\n",
    "tracker.completed_runs\n",
    "\n",
    "# Run experiments with checkpointing\n",
    "tracker.run_experiments(\n",
    "    datasets=datasets,\n",
    "    experiment_combinations=experiment_combinations,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    numeric_columns=numeric_columns,\n",
    "    categorical_cols=categorical_cols\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
